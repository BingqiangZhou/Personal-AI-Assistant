# =============================================================================
# Docker Compose - 统一配置 / Unified Configuration
# =============================================================================
# 使用方法 / Usage:
#   1. 复制 .env.example .env / Copy .env.example to .env
#   2. 根据需要修.env 配置 / Modify .env as needed
#   3. 启动服务 / Start services: docker compose up -d
#
# 启动的服/ Started Services:
#   - PostgreSQL (数据/ Database)
#   - Redis (缓存 / Cache)
#   - Backend API (后端服务)
#   - Celery Worker (后台任务处理 / Background tasks)
#   - Celery Beat (定时任务调度 / Scheduled tasks)
#   - Nginx (反向代理 / Reverse proxy)

services:
  # =============================================================================
  # PostgreSQL Database
  # =============================================================================
  postgres:
    image: postgres:15-alpine
    container_name: ${PROJECT_NAME:-personal_ai}_postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-personal_ai}
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "${DB_PORT:-127.0.0.1:5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-personal_ai}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always

  # =============================================================================
  # Redis Cache
  # =============================================================================
  redis:
    image: redis:7-alpine
    container_name: ${PROJECT_NAME:-personal_ai}_redis
    command: >
      sh -c 'if [ -z "$REDIS_PASSWORD" ]; then
               redis-server --appendonly yes;
             else
               redis-server --appendonly yes --requirepass "$REDIS_PASSWORD";
             fi'
    ports:
      - "${REDIS_PORT:-127.0.0.1:6379}:6379"
    volumes:
      - redis_data:/data
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: always

  # =============================================================================
  # Backend API
  # =============================================================================
  backend:
    build:
      context: ${BACKEND_SRC_DIR:-../backend}
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-personal_ai}_backend
    env_file:
      - ${BACKEND_ENV_FILE:-../backend/.env}
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-personal_ai}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0
      # Playwright configuration
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
      # Timezone for log timestamps / 日志时区
      - TZ=${TZ:-Asia/Shanghai}
    ports:
      - "${BACKEND_PUBLISH_PORT:-8000}:8000"
    volumes:
      - backend_uploads:/app/uploads
      - backend_data:/app/data
      - ${TRANSCRIPTION_STORAGE_DIR:-./storage/podcasts}:/app/storage/podcasts
      - ${TRANSCRIPTION_TEMP_DIR:-./temp/transcription}:/app/temp/transcription
      - ${LOG_DIR:-./logs}:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app_network
    restart: always
    # Resource limits for running Playwright Chromium
    # Increase memory and CPU for browser operations
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    # 本地与云端统一使用 gunicorn（本地可通过 BACKEND_CMD 增加 --reload）
    # Unified: gunicorn for both local and cloud
    command: ${BACKEND_CMD:-gunicorn app.main:app --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000 --workers 4 --timeout 120 --log-level info}
    # Use shared memory for Chromium
    shm_size: 2gb

  # =============================================================================
  # Celery Core Worker
  # =============================================================================
  celery_worker_core:
    build:
      context: ${BACKEND_SRC_DIR:-../backend}
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-personal_ai}_celery_worker_core
    env_file:
      - ${BACKEND_ENV_FILE:-../backend/.env}
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-personal_ai}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0
      # Playwright configuration
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
      # Timezone for log timestamps / 日志时区
      - TZ=${TZ:-Asia/Shanghai}
    volumes:
      - backend_data:/app/data
      - ${TRANSCRIPTION_STORAGE_DIR:-./storage/podcasts}:/app/storage/podcasts
      - ${TRANSCRIPTION_TEMP_DIR:-./temp/transcription}:/app/temp/transcription
      - ${LOG_DIR:-./logs}:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app_network
    restart: always
    # Resource limits for running Playwright Chromium
    # Worker needs more resources for transcription and browser operations
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    command: celery -A app.core.celery_app:celery_app worker --loglevel=${CELERY_LOG_LEVEL:-info} --concurrency=${CELERY_WORKERS_CORE:-2} -Q subscription_sync,ai_generation,maintenance
    # Use shared memory for Chromium
    shm_size: 2gb

  # =============================================================================
  # Celery Transcription Worker
  # =============================================================================
  celery_worker_transcription:
    build:
      context: ${BACKEND_SRC_DIR:-../backend}
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-personal_ai}_celery_worker_transcription
    env_file:
      - ${BACKEND_ENV_FILE:-../backend/.env}
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-personal_ai}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
      - TZ=${TZ:-Asia/Shanghai}
    volumes:
      - backend_data:/app/data
      - ${TRANSCRIPTION_STORAGE_DIR:-./storage/podcasts}:/app/storage/podcasts
      - ${TRANSCRIPTION_TEMP_DIR:-./temp/transcription}:/app/temp/transcription
      - ${LOG_DIR:-./logs}:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    command: celery -A app.core.celery_app:celery_app worker --loglevel=${CELERY_LOG_LEVEL:-info} --concurrency=${CELERY_WORKERS_TRANSCRIPTION:-2} -Q transcription
    shm_size: 2gb

  # =============================================================================
  # Celery Beat
  # =============================================================================
  celery_beat:
    build:
      context: ${BACKEND_SRC_DIR:-../backend}
      dockerfile: Dockerfile
    container_name: ${PROJECT_NAME:-personal_ai}_celery_beat
    env_file:
      - ${BACKEND_ENV_FILE:-../backend/.env}
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-personal_ai}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0
      # Timezone for log timestamps / 日志时区
      - TZ=${TZ:-Asia/Shanghai}
    volumes:
      - backend_data:/app/data
      - ${LOG_DIR:-./logs}:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      celery_worker_core:
        condition: service_started
      celery_worker_transcription:
        condition: service_started
    networks:
      - app_network
    restart: always
    command: celery -A app.core.celery_app:celery_app beat --loglevel=${CELERY_LOG_LEVEL:-info}

  # =============================================================================
  # Nginx Reverse Proxy (反向代理)
  # =============================================================================
  nginx:
    image: nginx:stable-alpine
    container_name: ${PROJECT_NAME:-personal_ai}_nginx
    restart: always
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    volumes:
      - ${NGINX_CONF_DIR:-./nginx}/nginx.conf:/etc/nginx/nginx.conf:ro
      - ${NGINX_CONF_DIR:-./nginx}/conf.d:/etc/nginx/templates:rw
      - ${NGINX_CERT_DIR:-./nginx/cert}:/etc/nginx/cert:ro
      - ${NGINX_LOG_DIR:-./nginx/logs}:/var/log/nginx
      - /etc/localtime:/etc/localtime:ro
      - ${NGINX_CONF_DIR:-./nginx}/docker-entrypoint.sh:/auto-config.sh:ro
    environment:
      # 域名配置 / Domain configuration
      - DOMAIN=${DOMAIN:-localhost}
      - SSL_CERT_PATH=${SSL_CERT_PATH:-/etc/nginx/cert/fullchain.pem}
      - SSL_KEY_PATH=${SSL_KEY_PATH:-/etc/nginx/cert/privkey.pem}
    entrypoint:
      - /bin/sh
      - -c
      - |
        if [ -f /auto-config.sh ]; then
          echo "=== Running auto-configuration ==="
          sh /auto-config.sh || echo "Warning: auto-config script failed, continuing..."
        fi
        echo "=== Starting Nginx ==="
        exec /docker-entrypoint.sh nginx -g 'daemon off;'
    depends_on:
      - backend
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  backend_uploads:
    driver: local
  backend_data:
    driver: local

networks:
  app_network:
    driver: bridge
