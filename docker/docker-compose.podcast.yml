services:
  # PostgreSQL Database (优化版本 - 适合个人使用)
  postgres:
    image: postgres:15-alpine
    container_name: podcast_postgres
    environment:
      POSTGRES_DB: personal_ai
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: MySecurePass2024!
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - podcast_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Cache (单DB，适合个人使用)
  redis:
    image: redis:7-alpine
    container_name: podcast_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - podcast_network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Backend API (Podcast Feature Optimized)
  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: podcast_backend
    ports:
      - "8000:8000"
    environment:
      # 使用Docker网络名称，而不是localhost
      - DATABASE_URL=postgresql+asyncpg://admin:MySecurePass2024!@postgres:5432/personal_ai
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0

      # 播客功能配置
      - SECRET_KEY=  # SECRET_KEY will be auto-generated by backend
      - ENVIRONMENT=production
      - DATA_DIR=data

      # 可�? AI总结配置 (如果没有OpenAI key会自动降�?
      - OPENAI_API_KEY=sk-your-api-key-here

      # 隐私模式
      - LLM_CONTENT_SANITIZE_MODE=standard

      # 播客限制
      - PODCAST_SUBSCRIPTION_LIMIT=20
    volumes:
      - ../backend:/app
      - backend_uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - podcast_network
    restart: unless-stopped
    # 使用生产环境的uvicorn配置
    # 如果首次启动失败，volumes可能需要等待Docker Desktop就绪后再重启
    command: >
      sh -c "sleep 5 &&
             uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 2 --log-level info"

  # (可�? Celery Worker - 如果需要后台任务才启用
  # celery_worker:
  #   build:
  #     context: ./backend
  #     dockerfile: Dockerfile
  #   container_name: podcast_celery_worker
  #   environment:
  #     - DATABASE_URL=postgresql+asyncpg://admin:~0,8@postgres:5432/personal_ai
  #     - REDIS_URL=redis://redis:6379
  #     - CELERY_BROKER_URL=redis://redis:6379/0
  #     - CELERY_RESULT_BACKEND=redis://redis:6379/0
  #   volumes:
  #     - ./backend:/app
  #   depends_on:
  #     - postgres
  #     - redis
  #   networks:
  #     - podcast_network
  #   command: celery -A app.integration.celery_app worker --loglevel=info --concurrency=2

volumes:
  postgres_data:
  redis_data:
  backend_uploads:

networks:
  podcast_network:
    driver: bridge
