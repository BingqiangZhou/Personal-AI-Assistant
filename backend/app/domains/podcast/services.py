"""
æ’­å®¢ä¸šåŠ¡é€»è¾‘æœåŠ¡ - Podcast Services

æ ¸å¿ƒæœåŠ¡:
1. PodcastController: ç®¡ç†æ’­å®¢è®¢é˜…å’Œå•é›†
2. PodcastSummaryService: AIæ€»ç»“ç”Ÿæˆ
3. PodcastSyncService: RSSè½®è¯¢å’ŒåŒæ­¥
"""

import logging
from typing import List, Tuple, Optional, Dict, Any
from datetime import datetime, timedelta
import asyncio

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.core.config import settings
from app.core.llm_privacy import ContentSanitizer
from app.core.redis import PodcastRedis
from app.domains.podcast.repositories import PodcastRepository
from app.domains.podcast.models import PodcastEpisode
from app.domains.podcast.schemas import PodcastSubscriptionCreate
from app.domains.subscription.models import Subscription
from app.domains.assistant.models import Conversation, Message
from app.integration.podcast.security import PodcastSecurityValidator
from app.integration.podcast.secure_rss_parser import SecureRSSParser, PodcastFeed

logger = logging.getLogger(__name__)


class PodcastService:
    """
    æ’­å®¢æ ¸å¿ƒæœåŠ¡ - ç»Ÿä¸€æ¥å£
    """

    def __init__(self, db: AsyncSession, user_id: int):
        self.db = db
        self.user_id = user_id
        self.repo = PodcastRepository(db)
        self.redis = PodcastRedis()
        self.sanitizer = ContentSanitizer(mode=settings.LLM_CONTENT_SANITIZE_MODE)
        self.security = PodcastSecurityValidator()
        self.parser = SecureRSSParser(user_id)
        from app.domains.podcast.transcription_manager import DatabaseBackedTranscriptionService
        self.transcription_service = DatabaseBackedTranscriptionService(db)

        # AI text generation service for summaries
        from app.domains.ai.services import TextGenerationService
        self.text_generation = TextGenerationService(db)

    # === è®¢é˜…ç®¡ç† ===

    async def add_subscription(
        self,
        feed_url: str,
        category_ids: Optional[List[int]] = None
    ) -> Tuple[Subscription, List[PodcastEpisode]]:
        """
        æ·»åŠ æ’­å®¢è®¢é˜…
        è¿”å›: (subscription, new_episodes)
        """
        # 1. éªŒè¯å¹¶è§£æRSS
        success, feed, error = await self.parser.fetch_and_parse_feed(feed_url)
        if not success:
            raise ValueError(f"æ— æ³•è§£ææ’­å®¢: {error}")

        # 2. æ£€æŸ¥è®¢é˜…æ•°é‡é™åˆ¶
        existing_subs = await self.repo.get_user_subscriptions(self.user_id)
        if len(existing_subs) >= settings.MAX_PODCAST_SUBSCRIPTIONS:
            raise ValueError(f"å·²è¾¾åˆ°æœ€å¤§è®¢é˜…æ•°é‡: {settings.MAX_PODCAST_SUBSCRIPTIONS}")

        # 3. åˆ›å»ºæˆ–æ›´æ–°è®¢é˜…
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "author": feed.author,
            "language": feed.language,
            "categories": feed.categories,
            "explicit": feed.explicit,
            "image_url": feed.image_url,
            "podcast_type": feed.podcast_type,
            "link": feed.link,
            "total_episodes": len(feed.episodes),
            "platform": feed.platform
        }

        subscription = await self.repo.create_or_update_subscription(
            self.user_id,
            feed_url,
            feed.title,
            feed.description,
            None,  # custom_name
            metadata=metadata
        )

        # 4. å¤„ç†åˆ†ç±»å…³è”
        if category_ids:
            await self.repo.update_subscription_categories(subscription.id, category_ids)

        # 5. ä¿å­˜å¹¶æ€»ç»“æ–°å•é›†
        new_episodes = []
        for episode in feed.episodes:  # æ‰€æœ‰å•é›†
            saved_episode, is_new = await self.repo.create_or_update_episode(
                subscription_id=subscription.id,
                title=episode.title,
                description=episode.description,
                audio_url=episode.audio_url,
                published_at=episode.published_at,
                audio_duration=episode.duration,
                transcript_url=episode.transcript_url,
                item_link=episode.link,
                metadata={"feed_title": feed.title}
            )

            if is_new:
                new_episodes.append(saved_episode)
                # ä¸åœ¨æ·»åŠ è®¢é˜…æ—¶è§¦å‘AIæ€»ç»“ï¼Œé¿å…ä¼šè¯å†²çª
                # ç”¨æˆ·å¯ä»¥åç»­æ‰‹åŠ¨è§¦å‘æ€»ç»“

        logger.info(f"ç”¨æˆ·{self.user_id} æ·»åŠ æ’­å®¢: {feed.title}, {len(new_episodes)}æœŸæ–°èŠ‚ç›®")
        return subscription, new_episodes

    async def add_subscriptions_batch(
        self,
        subscriptions_data: List[PodcastSubscriptionCreate]
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡æ·»åŠ æ’­å®¢è®¢é˜…"""
        logger.info(f"å¼€å§‹æ‰¹é‡æ·»åŠ è®¢é˜…: {len(subscriptions_data)}ä¸ª")
        results = []
        for sub_data in subscriptions_data:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è®°å½• (é€šè¿‡URL)
                existing = await self.repo.get_subscription_by_url(self.user_id, sub_data.feed_url)
                if existing:
                    results.append({
                        "source_url": sub_data.feed_url,
                        "status": "skipped",
                        "message": "Subscription already exists"
                    })
                    continue
                
                # æ·»åŠ è®¢é˜…
                subscription, new_episodes = await self.add_subscription(
                    sub_data.feed_url,
                    sub_data.category_ids
                )
                
                results.append({
                    "source_url": sub_data.feed_url,
                    "status": "success",
                    "id": subscription.id,
                    "title": subscription.title,
                    "new_episodes": len(new_episodes)
                })
            except Exception as e:
                logger.error(f"æ‰¹é‡æ·»åŠ è®¢é˜…å¤±è´¥ {sub_data.feed_url}: {e}")
                # å›æ»šSessionä»¥æ¸…é™¤é”™è¯¯çŠ¶æ€
                try:
                    await self.repo.db.rollback()
                except Exception as rollback_error:
                    logger.warning(f"å›æ»šSessionå¤±è´¥: {rollback_error}")
                results.append({
                    "source_url": sub_data.feed_url,
                    "status": "error",
                    "message": str(e)
                })
        return results

    async def list_subscriptions(
        self,
        filters: Optional[dict] = None,
        page: int = 1,
        size: int = 20
    ) -> Tuple[List[dict], int]:
        """åˆ—å‡ºç”¨æˆ·çš„æ‰€æœ‰æ’­å®¢è®¢é˜…ï¼ˆæ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤ï¼‰"""
        subscriptions, total = await self.repo.get_user_subscriptions_paginated(
            self.user_id,
            page=page,
            size=size,
            filters=filters
        )

        # Batch fetch episode counts and recent episodes for all subscriptions (N+1 query fix)
        subscription_ids = [sub.id for sub in subscriptions]
        episode_counts = await self.repo.get_episodes_counts_batch(subscription_ids)
        episodes_batch = await self.repo.get_subscription_episodes_batch(
            subscription_ids,
            limit_per_subscription=settings.PODCAST_RECENT_EPISODES_LIMIT
        )

        # Batch fetch playback states for all episodes
        all_episode_ids = []
        for ep_list in episodes_batch.values():
            all_episode_ids.extend([ep.id for ep in ep_list])
        playback_states = await self.repo.get_playback_states_batch(self.user_id, all_episode_ids)

        results = []
        for sub in subscriptions:
            # Get episodes for this subscription
            episodes = episodes_batch.get(sub.id, [])

            # Calculate unplayed count using batch-fetched playback states
            unplayed_count = 0
            for ep in episodes:
                playback = playback_states.get(ep.id)
                if not playback or not playback.current_position or \
                   (ep.audio_duration and playback.current_position < ep.audio_duration * 0.9):
                    unplayed_count += 1

            episode_count = episode_counts.get(sub.id, 0)

            # ä»è®¢é˜…é…ç½®ä¸­æå–å›¾ç‰‡URLå’Œå…¶ä»–å…ƒæ•°æ®
            config = sub.config or {}
            image_url = config.get("image_url")
            author = config.get("author")
            platform = config.get("platform")
            # å¤„ç†categoriesæ ¼å¼ - ç»Ÿä¸€è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            raw_categories = config.get("categories") or []
            categories = []
            for cat in raw_categories:
                if isinstance(cat, str):
                    categories.append({"name": cat})
                elif isinstance(cat, dict):
                    categories.append(cat)
                else:
                    categories.append({"name": str(cat)})
            podcast_type = config.get("podcast_type")
            language = config.get("language")
            explicit = config.get("explicit", False)
            link = config.get("link")

            # è·å–é…ç½®ä¸­çš„æ€»é›†æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            total_episodes_from_config = config.get("total_episodes")

            # å°†æœ€æ–°å•é›†è½¬æ¢ä¸ºå­—å…¸
            latest_episode_dict = None
            if episodes:
                latest = episodes[0]
                latest_episode_dict = {
                    "id": latest.id,
                    "title": latest.title,
                    "audio_url": latest.audio_url,
                    "duration": latest.audio_duration,
                    "published_at": latest.published_at,
                    "ai_summary": latest.ai_summary,
                    "status": latest.status
                }

            results.append({
                "id": sub.id,
                "user_id": sub.user_id,
                "title": sub.title,
                "description": sub.description,
                "source_url": sub.source_url,
                "status": sub.status,
                "last_fetched_at": sub.last_fetched_at,
                "error_message": sub.error_message,
                "fetch_interval": sub.fetch_interval,
                "episode_count": episode_count,
                "unplayed_count": unplayed_count,
                "latest_episode": latest_episode_dict,
                "categories": categories,
                "image_url": image_url,
                "author": author,
                "platform": platform,
                "podcast_type": podcast_type,
                "language": language,
                "explicit": explicit,
                "link": link,
                "total_episodes_from_config": total_episodes_from_config,
                "created_at": sub.created_at,
                "updated_at": sub.updated_at
            })

        return results, total

    async def list_episodes(
        self,
        filters: Optional[dict] = None,
        page: int = 1,
        size: int = 20
    ) -> Tuple[List[dict], int]:
        """è·å–æ’­å®¢å•é›†åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤ï¼‰- æ”¯æŒç¼“å­˜"""
        # Extract subscription_id from filters for caching
        subscription_id = filters.get('subscription_id') if filters else None

        # Try cache first if filtering by subscription (10 minutes TTL)
        if subscription_id:
            cached = await self.redis.get_episode_list(subscription_id, page, size)
            if cached:
                logger.info(f"Cache HIT for episode list: sub_id={subscription_id}, page={page}")
                return cached['results'], cached['total']

            logger.info(f"Cache MISS for episode list: sub_id={subscription_id}, page={page}, querying database")

        episodes, total = await self.repo.get_episodes_paginated(
            self.user_id,
            page=page,
            size=size,
            filters=filters
        )

        # Batch fetch all playback states to avoid N+1 query problem
        episode_ids = [ep.id for ep in episodes]
        playback_states = await self.repo.get_playback_states_batch(self.user_id, episode_ids)

        # Use helper method to build response (eliminates duplicate code)
        results = self._build_episode_response(episodes, playback_states)

        # Cache the results if filtering by subscription
        if subscription_id:
            await self.redis.set_episode_list(subscription_id, page, size, {
                'results': results,
                'total': total
            })

        return results, total

    async def search_podcasts(
        self,
        query: str,
        search_in: str = "all",
        page: int = 1,
        size: int = 20
    ) -> Tuple[List[dict], int]:
        """æœç´¢æ’­å®¢å†…å®¹ - æ”¯æŒç¼“å­˜"""
        # Try cache first
        cached = await self.redis.get_search_results(query, search_in, page, size)
        if cached:
            logger.info(f"Cache HIT for search: {query}")
            return cached['results'], cached['total']

        logger.info(f"Cache MISS for search: {query}, querying database")

        episodes, total = await self.repo.search_episodes(
            self.user_id,
            query=query,
            search_in=search_in,
            page=page,
            size=size
        )

        # Batch fetch playback states for all episodes to avoid N+1 query
        episode_ids = [ep.id for ep in episodes]
        playback_states = await self.repo.get_playback_states_batch(self.user_id, episode_ids)

        # Use helper method to build response (eliminates duplicate code)
        results = self._build_episode_response(episodes, playback_states)

        # Add relevance scores if present
        for i, ep in enumerate(episodes):
            results[i]["relevance_score"] = getattr(ep, 'relevance_score', 1.0)

        # Cache the results (5 minutes TTL)
        await self.redis.set_search_results(query, search_in, page, size, {
            'results': results,
            'total': total
        })

        return results, total

    async def refresh_subscription(self, subscription_id: int) -> List[PodcastEpisode]:
        """åˆ·æ–°æ’­å®¢è®¢é˜…ï¼Œè·å–æœ€æ–°å•é›†"""
        # è·å–è®¢é˜…ä¿¡æ¯
        sub = await self.repo.get_subscription_by_id(self.user_id, subscription_id)
        if not sub:
            raise ValueError("è®¢é˜…ä¸å­˜åœ¨")

        # è§£æRSS
        success, feed, error = await self.parser.fetch_and_parse_feed(sub.source_url)
        if not success:
            raise ValueError(f"åˆ·æ–°å¤±è´¥: {error}")

        # ä¿å­˜æ–°å•é›†
        new_episodes = []
        for episode in feed.episodes:
            saved_episode, is_new = await self.repo.create_or_update_episode(
                subscription_id=subscription_id,
                title=episode.title,
                description=episode.description,
                audio_url=episode.audio_url,
                published_at=episode.published_at,
                audio_duration=episode.duration,
                transcript_url=episode.transcript_url,
                item_link=episode.link,
                metadata={"feed_title": feed.title, "refreshed_at": datetime.utcnow().isoformat()}
            )

            if is_new:
                new_episodes.append(saved_episode)
                # å¼‚æ­¥è§¦å‘è½¬å½•ä»»åŠ¡ï¼ˆä½¿ç”¨Celeryï¼‰
                from app.domains.podcast.tasks import process_audio_transcription
                try:
                    # åˆ›å»ºå¹¶è°ƒåº¦è½¬å½•ä»»åŠ¡
                    task = await self.transcription_service.start_transcription(saved_episode.id)
                    logger.info(f"å·²ä¸ºepisode {saved_episode.id} åˆ›å»ºå¹¶è°ƒåº¦è½¬å½•ä»»åŠ¡ {task.id}")
                except Exception as e:
                    logger.error(f"åˆ›å»ºè½¬å½•ä»»åŠ¡å¤±è´¥ episode {saved_episode.id}: {e}")
                
                # å¼‚æ­¥è§¦å‘AIæ€»ç»“
                asyncio.create_task(self._generate_summary_task(saved_episode))

        # æ›´æ–°è®¢é˜…çš„æœ€åæŠ“å–æ—¶é—´ï¼ˆä½¿ç”¨æœ€æ–°åˆ†é›†çš„å‘å¸ƒæ—¶é—´ï¼‰
        await self.repo.update_subscription_fetch_time(subscription_id, feed.last_fetched)

        # åªåœ¨æœ‰æ–°èŠ‚ç›®æ—¶è¾“å‡ºæ—¥å¿—
        if len(new_episodes) > 0:
            logger.info(f"ç”¨æˆ·{self.user_id} åˆ·æ–°è®¢é˜…: {sub.title}, å‘ç° {len(new_episodes)}æœŸæ–°èŠ‚ç›®")
        return new_episodes

    async def reparse_subscription(self, subscription_id: int, force_all: bool = False) -> dict:
        """
        é‡æ–°è§£æè®¢é˜…çš„æ‰€æœ‰å•é›†ï¼ˆç”¨äºä¿®å¤è§£æä¸å…¨çš„é—®é¢˜ï¼‰

        Args:
            subscription_id: è®¢é˜…ID
            force_all: æ˜¯å¦å¼ºåˆ¶é‡æ–°è§£ææ‰€æœ‰å•é›†ï¼Œé»˜è®¤åªè§£æç¼ºå¤±çš„å•é›†

        Returns:
            dict: åŒ…å«è§£æç»Ÿè®¡ä¿¡æ¯
        """
        # è·å–è®¢é˜…ä¿¡æ¯
        sub = await self.repo.get_subscription_by_id(self.user_id, subscription_id)
        if not sub:
            raise ValueError("è®¢é˜…ä¸å­˜åœ¨")

        logger.info(f"ç”¨æˆ·{self.user_id} å¼€å§‹é‡æ–°è§£æè®¢é˜…: {sub.title}")

        # è§£æRSS
        success, feed, error = await self.parser.fetch_and_parse_feed(sub.source_url)
        if not success:
            raise ValueError(f"é‡æ–°è§£æå¤±è´¥: {error}")

        # è·å–å½“å‰å·²å­˜åœ¨çš„å•é›†item_links
        existing_item_links = set()
        if not force_all:
            existing_episodes = await self.repo.get_subscription_episodes(subscription_id, limit=None)
            existing_item_links = {ep.item_link for ep in existing_episodes if ep.item_link}
        # ä¿å­˜å•é›†
        processed = 0
        new_episodes = 0
        updated_episodes = 0
        failed = 0

        for episode in feed.episodes:
            # å¦‚æœä¸æ˜¯å¼ºåˆ¶å…¨éƒ¨é‡æ–°è§£æï¼Œè·³è¿‡å·²å­˜åœ¨çš„
            if not force_all and episode.link in existing_item_links:
                continue

            try:
                # Debug: è®°å½• episode.link çš„å€¼
                logger.info(f"ğŸ”— [REPARSE] Episode: {episode.title[:50]}...")
                logger.info(f"   - episode.link: {episode.link}")

                saved_episode, is_new = await self.repo.create_or_update_episode(
                    subscription_id=subscription_id,
                    title=episode.title,
                    description=episode.description,
                    audio_url=episode.audio_url,
                    published_at=episode.published_at,
                    audio_duration=episode.duration,
                    transcript_url=episode.transcript_url,
                    item_link=episode.link,
                    metadata={
                        "feed_title": feed.title,
                        "reparsed_at": datetime.utcnow().isoformat(),
                        "item_link": episode.link
                    }
                )

                processed += 1
                if is_new:
                    new_episodes += 1
                    # ä¸åœ¨reparseä¸­è§¦å‘AIæ€»ç»“ï¼Œé¿å…ä¼šè¯å†²çª
                    # ç”¨æˆ·å¯ä»¥åç»­æ‰‹åŠ¨è§¦å‘æ€»ç»“
                else:
                    updated_episodes += 1

            except Exception as e:
                # Use explicit logger access to avoid scoping issues
                logging.getLogger(__name__).error(f"é‡æ–°è§£æå•é›†å¤±è´¥: {episode.title}, é”™è¯¯: {e}")
                failed += 1

        # æ›´æ–°è®¢é˜…é…ç½®å’Œæœ€åæŠ“å–æ—¶é—´
        metadata = {
            "author": feed.author,
            "language": feed.language,
            "categories": feed.categories,
            "explicit": feed.explicit,
            "image_url": feed.image_url,
            "podcast_type": feed.podcast_type,
            "link": feed.link,
            "total_episodes": len(feed.episodes),
            "platform": feed.platform,
            "reparsed_at": datetime.utcnow().isoformat()
        }

        await self.repo.update_subscription_metadata(subscription_id, metadata)
        await self.repo.update_subscription_fetch_time(subscription_id, feed.last_fetched)

        result = {
            "subscription_id": subscription_id,
            "subscription_title": sub.title,
            "total_episodes_in_feed": len(feed.episodes),
            "processed": processed,
            "new_episodes": new_episodes,
            "updated_episodes": updated_episodes,
            "failed": failed,
            "message": f"é‡æ–°è§£æå®Œæˆ: å¤„ç†{processed}ä¸ªï¼Œæ–°å¢{new_episodes}ä¸ªï¼Œæ›´æ–°{updated_episodes}ä¸ªï¼Œå¤±è´¥{failed}ä¸ª"
        }

        logger.info(f"ç”¨æˆ·{self.user_id} é‡æ–°è§£æè®¢é˜…å®Œæˆ: {result}")
        return result

    async def get_playback_state(self, episode_id: int) -> Optional[dict]:
        """è·å–æ’­æ”¾çŠ¶æ€"""
        playback = await self.repo.get_playback_state(self.user_id, episode_id)
        if not playback:
            return None

        episode = await self.repo.get_episode_by_id(episode_id)
        if not episode:
            return None

        progress_percentage = 0
        remaining_time = 0
        if episode.audio_duration and episode.audio_duration > 0:
            progress_percentage = (playback.current_position / episode.audio_duration) * 100
            remaining_time = max(0, episode.audio_duration - playback.current_position)

        return {
            "episode_id": episode_id,
            "current_position": playback.current_position,
            "is_playing": playback.is_playing,
            "playback_rate": playback.playback_rate,
            "play_count": playback.play_count,
            "last_updated_at": playback.last_updated_at,
            "progress_percentage": round(progress_percentage, 2),
            "remaining_time": remaining_time
        }

    async def get_user_stats(self) -> dict:
        """è·å–ç”¨æˆ·æ’­å®¢ç»Ÿè®¡ - ä½¿ç”¨é«˜æ•ˆèšåˆæŸ¥è¯¢å’Œç¼“å­˜"""
        # Try cache first (30 minutes TTL)
        cached = await self.redis.get_user_stats(self.user_id)
        if cached:
            logger.info(f"Cache HIT for user stats: user_id={self.user_id}")
            return cached

        logger.info(f"Cache MISS for user stats: user_id={self.user_id}, querying database")

        # ä½¿ç”¨èšåˆæŸ¥è¯¢è·å–åŸºç¡€ç»Ÿè®¡ï¼ˆO(1) vs O(n*m)ï¼‰
        stats = await self.repo.get_user_stats_aggregated(self.user_id)

        # æœ€è¿‘æ’­æ”¾
        recently_played = await self.repo.get_recently_played(self.user_id, limit=5)

        # è¿ç»­æ”¶å¬å¤©æ•°
        listening_streak = await self._calculate_listening_streak()

        # çƒ­é—¨åˆ†ç±»ï¼ˆTODO: å®ç°åˆ†ç±»ç»Ÿè®¡ï¼‰
        top_categories = []

        result = {
            **stats,
            "recently_played": recently_played,
            "top_categories": top_categories,
            "listening_streak": listening_streak
        }

        # Cache the results (30 minutes TTL)
        await self.redis.set_user_stats(self.user_id, result)

        return result

    async def get_recommendations(self, limit: int = 10) -> List[dict]:
        """è·å–æ’­å®¢æ¨è"""
        # åŸºäºç”¨æˆ·æ”¶å¬å†å²æ¨è
        # è¿™é‡Œå®ç°ç®€å•çš„æ¨èé€»è¾‘ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•

        # 1. è·å–ç”¨æˆ·å–œæ¬¢çš„æ’­å®¢ï¼ˆæ’­æ”¾å®Œæˆç‡é«˜çš„ï¼‰
        liked_episodes = await self.repo.get_liked_episodes(self.user_id, limit=20)

        # 2. åŸºäºä¸»é¢˜ç›¸ä¼¼æ€§æ¨è
        # TODO: å®ç°åŸºäºå†…å®¹çš„æ¨èç®—æ³•

        # 3. è¿”å›æ¨èç»“æœ
        recommendations = []
        for ep in liked_episodes[:limit]:
            recommendations.append({
                "episode_id": ep.id,
                "title": ep.title,
                "description": ep.description[:150] + "...",
                "subscription_title": ep.subscription.title,
                "recommendation_reason": "åŸºäºæ‚¨æ”¶å¬å†å²æ¨è",
                "match_score": 0.85
            })

        return recommendations

    async def get_subscription_details(self, subscription_id: int) -> Optional[dict]:
        """è·å–è®¢é˜…è¯¦æƒ…åŠå•é›†åˆ—è¡¨"""
        sub = await self.repo.get_subscription_by_id(self.user_id, subscription_id)
        if not sub:
            return None

        episodes = await self.repo.get_subscription_episodes(
            subscription_id,
            limit=settings.PODCAST_EPISODE_BATCH_SIZE
        )
        pending_count = len([e for e in episodes if not e.ai_summary])

        # ä»è®¢é˜…é…ç½®ä¸­æå–å›¾ç‰‡URLå’Œå…¶ä»–å…ƒæ•°æ®
        config = sub.config or {}
        image_url = config.get("image_url")
        author = config.get("author")
        categories = config.get("categories") or []
        podcast_type = config.get("podcast_type")
        language = config.get("language")
        explicit = config.get("explicit", False)
        link = config.get("link")

        return {
            "id": sub.id,
            "title": sub.title,
            "description": sub.description,
            "source_url": sub.source_url,
            "image_url": image_url,
            "author": author,
            "categories": categories,
            "podcast_type": podcast_type,
            "language": language,
            "explicit": explicit,
            "link": link,
            "episode_count": len(episodes),
            "pending_summaries": pending_count,
            "episodes": [{
                "id": ep.id,
                "title": ep.title,
                "description": ep.description[:100] + "..." if len(ep.description) > 100 else ep.description,
                "audio_url": ep.audio_url,
                "duration": ep.audio_duration,
                "published_at": ep.published_at,
                "has_summary": ep.ai_summary is not None,
                "summary": ep.ai_summary[:200] + "..." if ep.ai_summary and len(ep.ai_summary) > 200 else ep.ai_summary,
                "ai_confidence": ep.ai_confidence_score,
                "play_count": ep.play_count
            } for ep in episodes]
        }

    async def remove_subscription(self, subscription_id: int) -> bool:
        """
        åˆ é™¤è®¢é˜…ï¼ˆåœ¨å•ä¸ªäº‹åŠ¡ä¸­å®ŒæˆéªŒè¯å’Œåˆ é™¤ï¼Œé¿å…ç«æ€æ¡ä»¶ï¼‰

        åˆ é™¤é¡ºåºï¼ˆæŒ‰å¤–é”®ä¾èµ–å…³ç³»ï¼‰:
        1. conversations (é€šè¿‡ episode_id)
        2. playback_progress (podcast_playback_states)
        3. transcriptions (transcription_tasks)
        4. episodes (podcast_episodes)
        5. subscriptions
        """
        try:
            # åœ¨å•ä¸ªäº‹åŠ¡ä¸­å®Œæˆæ‰€æœ‰æ“ä½œ
            async with self.db.begin():
                # 1. éªŒè¯è®¢é˜…å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
                sub = await self._validate_and_get_subscription(subscription_id)
                if not sub:
                    return False

                # ä¿å­˜æ ‡é¢˜ç”¨äºæ—¥å¿—ï¼ˆåœ¨äº‹åŠ¡æäº¤å‰ï¼‰
                sub_title = sub.title

                # 2. è·å–è¯¥è®¢é˜…çš„æ‰€æœ‰ episode_id
                episode_ids = await self._get_episode_ids_for_subscription(subscription_id)

                # 3. æŒ‰ä¾èµ–é¡ºåºåˆ é™¤æ‰€æœ‰ç›¸å…³å®ä½“
                await self._delete_subscription_related_entities(subscription_id, episode_ids)

            # äº‹åŠ¡æˆåŠŸæäº¤
            logger.info(f"ç”¨æˆ·{self.user_id} åˆ é™¤è®¢é˜…: {sub_title}")
            return True

        except Exception as e:
            logger.error(f"åˆ é™¤è®¢é˜… {subscription_id} å¤±è´¥: {e}")
            # äº‹åŠ¡è‡ªåŠ¨å›æ»š
            raise

    # === å•é›†ç®¡ç†ä¸AIæ€»ç»“ ===

    async def get_episode_by_id(self, episode_id: int) -> Optional[PodcastEpisode]:
        """è·å–å•é›†è¯¦æƒ…"""
        return await self.repo.get_episode_by_id(episode_id, self.user_id)

    async def get_subscription_by_id(self, subscription_id: int) -> Optional[Subscription]:
        """è·å–è®¢é˜…è¯¦æƒ…"""
        return await self.repo.get_subscription_by_id(self.user_id, subscription_id)

    async def get_episode_with_summary(self, episode_id: int) -> Optional[dict]:
        """è·å–å•é›†è¯¦æƒ…å’ŒAIæ€»ç»“"""
        episode = await self.repo.get_episode_by_id(episode_id, self.user_id)
        if not episode:
            return None

        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„æ€»ç»“
        if not episode.ai_summary and episode.status == "pending_summary":
            # è§¦å‘åå°æ€»ç»“
            asyncio.create_task(self._generate_summary_task(episode))

        playback = await self.repo.get_playback_state(self.user_id, episode_id)

        # ä»è®¢é˜…é…ç½®ä¸­æå–å›¾ç‰‡URLå’Œå…¶ä»–å…ƒæ•°æ®
        subscription_image_url = None
        subscription_author = None
        subscription_categories = []
        if episode.subscription and episode.subscription.config:
            config = episode.subscription.config
            subscription_image_url = config.get("image_url")
            subscription_author = config.get("author")
            subscription_categories = config.get("categories") or []

        return {
            "id": episode.id,
            "subscription_id": episode.subscription_id,
            "title": episode.title,
            "description": episode.description,
            "audio_url": episode.audio_url,
            "audio_duration": episode.audio_duration,
            "audio_file_size": episode.audio_file_size,
            "published_at": episode.published_at,
            "image_url": episode.image_url,
            "item_link": episode.item_link,
            "subscription_image_url": subscription_image_url,
            "transcript_url": episode.transcript_url,
            "transcript_content": episode.transcript_content,
            "ai_summary": episode.ai_summary,
            "summary_version": episode.summary_version,
            "ai_confidence_score": episode.ai_confidence_score,
            "play_count": episode.play_count,
            "last_played_at": episode.last_played_at,
            "season": episode.season,
            "episode_number": episode.episode_number,
            "explicit": episode.explicit,
            "status": episode.status,
            "metadata": episode.metadata_json or {},
            "created_at": episode.created_at,
            "updated_at": episode.updated_at,
            "playback_position": playback.current_position if playback else None,
            "is_playing": playback.is_playing if playback else False,
            "playback_rate": playback.playback_rate if playback else 1.0,
            "is_played": None,
            "subscription": {
                "id": episode.subscription.id,
                "title": episode.subscription.title,
                "description": episode.subscription.description,
                "image_url": subscription_image_url,
                "author": subscription_author,
                "categories": subscription_categories
            } if episode.subscription else None,
            "related_episodes": []
        }

    async def generate_summary_for_episode(self, episode_id: int) -> str:
        """
        ä¸ºæŒ‡å®šå•é›†ç”ŸæˆAIæ€»ç»“ï¼ˆåŒæ­¥æ–¹å¼ï¼Œç”¨äºæ˜ç¡®éœ€è¦ç­‰å¾…çš„åœºæ™¯ï¼‰
        """
        episode = await self.repo.get_episode_by_id(episode_id, self.user_id)
        if not episode:
            raise ValueError("Episode not found")

        if episode.ai_summary:
            return episode.ai_summary

        return await self._generate_summary(episode)

    async def regenerate_summary(self, episode_id: int, force: bool = False) -> str:
        """
        é‡æ–°ç”Ÿæˆæ€»ç»“
        force: å³ä½¿å·²æœ‰æ€»ç»“ä¹Ÿé‡æ–°ç”Ÿæˆ
        """
        episode = await self.repo.get_episode_by_id(episode_id, self.user_id)
        if not episode:
            raise ValueError("Episode not found")

        if episode.ai_summary and not force:
            return episode.ai_summary

        return await self._generate_summary(episode, version="v2")

    async def get_pending_summaries(self) -> List[dict]:
        """è·å–å¾…æ€»ç»“çš„å•é›†"""
        subscriptions = await self.repo.get_user_subscriptions(self.user_id)
        results = []

        for sub in subscriptions:
            pending = await self.repo.get_unsummarized_episodes(sub.id)
            for episode in pending:
                results.append({
                    "episode_id": episode.id,
                    "subscription_title": sub.title,
                    "episode_title": episode.title,
                    "size_estimate": len(episode.description) + (len(episode.transcript_content) or 0)
                })

        return results

    # === æ’­æ”¾ä¸è¿›åº¦ç®¡ç† ===

    async def update_playback_progress(
        self,
        episode_id: int,
        progress_seconds: int,
        is_playing: bool = False,
        playback_rate: float = 1.0
    ) -> dict:
        """æ›´æ–°æ’­æ”¾è¿›åº¦"""
        episode = await self.repo.get_episode_by_id(episode_id, self.user_id)
        if not episode:
            raise ValueError("Episode not found")

        playback = await self.repo.update_playback_progress(
            self.user_id,
            episode_id,
            progress_seconds,
            is_playing,
            playback_rate
        )

        return {
            "episode_id": episode_id,
            "progress": playback.current_position,
            "is_playing": playback.is_playing,
            "play_count": playback.play_count
        }

    # === ç§æœ‰è¾…åŠ©æ–¹æ³• ===

    async def _generate_summary_task(self, episode: PodcastEpisode):
        """
        åå°ä»»åŠ¡ï¼šå¼‚æ­¥ç”ŸæˆAIæ€»ç»“

        æ³¨æ„ï¼šæ­¤æ–¹æ³•è¿è¡Œåœ¨ç‹¬ç«‹çš„åå°ä»»åŠ¡ä¸­ï¼Œéœ€è¦åˆ›å»ºè‡ªå·±çš„æ•°æ®åº“ sessionï¼Œ
        é¿å…ä¸ä¸»è¯·æ±‚å…±äº« session å¯¼è‡´ SQLAlchemy å¹¶å‘é”™è¯¯ã€‚
        """
        from app.core.database import async_session_factory
        from app.domains.podcast.repositories import PodcastRepository
        from app.core.redis import PodcastRedis
        from app.core.config import settings
        from app.core.llm_privacy import ContentSanitizer

        # åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ session å’ŒæœåŠ¡å®ä¾‹
        async with async_session_factory() as session:
            try:
                # åˆ›å»ºç‹¬ç«‹çš„ repository å’Œ redis å®ä¾‹
                repo = PodcastRepository(session, PodcastRedis())
                sanitizer = ContentSanitizer(mode=settings.LLM_CONTENT_SANITIZE_MODE)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“ï¼ˆä½¿ç”¨ç‹¬ç«‹çš„ sessionï¼‰
                await session.rollback()  # ç¡®ä¿å¹²å‡€çŠ¶æ€
                stmt = select(PodcastEpisode).where(PodcastEpisode.id == episode.id)
                result = await session.execute(stmt)
                fresh_episode = result.scalar_one_or_none()

                if not fresh_episode:
                    logger.warning(f"Episode {episode.id} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ€»ç»“ç”Ÿæˆ")
                    return

                if fresh_episode.ai_summary:
                    logger.info(f"Episode {episode.id} å·²æœ‰æ€»ç»“ï¼Œè·³è¿‡")
                    return

                # ä½¿ç”¨ç‹¬ç«‹ session ç”Ÿæˆæ€»ç»“
                await self._generate_summary_with_session(
                    fresh_episode, session, repo, sanitizer
                )

            except Exception as e:
                logger.error(f"å¼‚æ­¥æ€»ç»“å¤±è´¥ episode:{episode.id}: {e}", exc_info=True)
                try:
                    await repo.mark_summary_failed(episode.id, str(e))
                except Exception as db_error:
                    logger.error(f"æ ‡è®°æ€»ç»“å¤±è´¥æ—¶å‡ºé”™ episode:{episode.id}: {db_error}")

    async def _generate_summary_with_session(
        self,
        episode: PodcastEpisode,
        session: AsyncSession,
        repo: PodcastRepository,
        sanitizer: ContentSanitizer
    ) -> str:
        """ä½¿ç”¨æŒ‡å®š session ç”Ÿæˆ AI æ€»ç»“

        Args:
            episode: æ’­å®¢å•é›†å¯¹è±¡
            session: SQLAlchemy å¼‚æ­¥ä¼šè¯
            repo: æ’­å®¢ä»“åº“å¯¹è±¡
            sanitizer: å†…å®¹å‡€åŒ–å™¨ï¼Œç”¨äºæ¸…ç†æ•æ„Ÿä¿¡æ¯

        Returns:
            str: AI ç”Ÿæˆçš„æ€»ç»“æ–‡æœ¬

        Raises:
            ValueError: å½“å†…å®¹å¤ªçŸ­æˆ–è¢«å®Œå…¨è¿‡æ»¤æ—¶
            asyncio.TimeoutError: å½“ç”Ÿæˆè¶…æ—¶æ—¶
        """
        import asyncio
        from sqlalchemy import select

        # æ£€æŸ¥é”ï¼Œé˜²æ­¢é‡å¤å¤„ç†
        lock_key = f"summary:{episode.id}"
        if not await self.redis.acquire_lock(lock_key, expire=300):
            return await self._wait_for_existing_summary(episode, session)

        try:
            # å‡†å¤‡å†…å®¹å¹¶ç”Ÿæˆæ€»ç»“
            raw_content, content_type, has_transcript = self._prepare_episode_content(episode)
            sanitized_prompt = self._sanitize_content(raw_content, sanitizer, content_type)

            # ç”Ÿæˆå¹¶ä¿å­˜æ€»ç»“
            summary = await self._call_llm_for_summary(
                episode_title=episode.title,
                content=sanitized_prompt,
                content_type=content_type
            )

            await repo.update_ai_summary(
                episode.id,
                summary,
                version="v1",
                transcript_used=has_transcript
            )

            logger.info(f"AIæ€»ç»“å®Œæˆ episode:{episode.id} ({content_type})")
            return summary

        except Exception as e:
            logger.error(f"ç”ŸæˆAIæ€»ç»“å¤±è´¥ episode:{episode.id}: {e}")
            await repo.mark_summary_failed(episode.id, str(e))
            raise
        finally:
            await self.redis.release_lock(lock_key)

    async def _generate_summary(self, episode: PodcastEpisode, version: str = "v1") -> str:
        """æ ¸å¿ƒAIæ€»ç»“ç”Ÿæˆé€»è¾‘"""
        # æ£€æŸ¥é”ï¼Œé˜²æ­¢é‡å¤å¤„ç†
        lock_key = f"summary:{episode.id}"
        if not await self.redis.acquire_lock(lock_key, expire=300):
            return await self._wait_for_existing_summary(episode, None)

        try:
            # å‡†å¤‡å†…å®¹å¹¶ç”Ÿæˆæ€»ç»“
            raw_content, content_type, has_transcript = self._prepare_episode_content(episode)
            sanitized_prompt = self._sanitize_content(raw_content, self.sanitizer, content_type)

            # ç”Ÿæˆå¹¶ä¿å­˜æ€»ç»“
            summary = await self._call_llm_for_summary(
                episode_title=episode.title,
                content=sanitized_prompt,
                content_type=content_type
            )

            await self.repo.update_ai_summary(
                episode.id,
                summary,
                version=version,
                transcript_used=has_transcript
            )

            logger.info(f"AIæ€»ç»“å®Œæˆ episode:{episode.id} ({content_type})")
            return summary

        except Exception as e:
            logger.error(f"ç”ŸæˆAIæ€»ç»“å¤±è´¥ episode:{episode.id}: {e}")
            await self.repo.mark_summary_failed(episode.id, str(e))
            raise
        finally:
            await self.redis.release_lock(lock_key)

    async def _call_llm_for_summary(
        self,
        episode_title: str,
        content: str,
        content_type: str
    ) -> str:
        """è°ƒç”¨LLM APIç”Ÿæˆæ€»ç»“ï¼Œæ”¯æŒfallbackæœºåˆ¶

        ä»æ•°æ®åº“ä¸­çš„AIæ¨¡å‹é…ç½®æŒ‰ä¼˜å…ˆçº§è·å–API keyï¼Œä¾æ¬¡å°è¯•æ¯ä¸ªé…ç½®ï¼Œ
        ç›´åˆ°æˆåŠŸç”Ÿæˆæ€»ç»“æˆ–æ‰€æœ‰é…ç½®éƒ½å¤±è´¥ã€‚

        Args:
            episode_title: æ’­å®¢å•é›†æ ‡é¢˜
            content: æ’­å®¢å†…å®¹ï¼ˆè½¬å½•æ–‡æœ¬æˆ–æè¿°ï¼‰
            content_type: å†…å®¹ç±»å‹æ ‡è¯†ï¼ˆtranscript/descriptionï¼‰

        Returns:
            str: AIç”Ÿæˆçš„æ€»ç»“æ–‡æœ¬ï¼Œå¦‚æœæ‰€æœ‰APIéƒ½å¤±è´¥åˆ™è¿”å›åŸºäºè§„åˆ™çš„æ€»ç»“

        Raises:
            APIConnectionError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
            RateLimitError: å½“è¶…è¿‡APIé€Ÿç‡é™åˆ¶æ—¶
        """
        # Delegate to AI domain service for text generation
        # This follows DDD principles by keeping AI-related logic in the AI domain
        return await self.text_generation.generate_podcast_summary(
            episode_title=episode_title,
            content=content,
            content_type=content_type,
            max_tokens=500
        )

    def _build_episode_response(
        self,
        episodes: List[PodcastEpisode],
        playback_states: Dict[int, Any]
    ) -> List[dict]:
        """
        Build episode response list with playback states and image URLs.

        Args:
            episodes: List of podcast episodes
            playback_states: Dictionary mapping episode_id to playback state

        Returns:
            List of episode response dictionaries
        """
        results = []
        for ep in episodes:
            # Get playback state from batch result
            playback = playback_states.get(ep.id)

            # Extract image URL from subscription config
            subscription_image_url = None
            if ep.subscription and ep.subscription.config:
                subscription_image_url = ep.subscription.config.get("image_url")

            # Use episode image_url if available, otherwise fallback to subscription image
            image_url = ep.image_url or subscription_image_url

            # Calculate is_played based on playback position and duration
            is_played = bool(
                playback and playback.current_position and
                ep.audio_duration and
                playback.current_position >= ep.audio_duration * 0.9
            )

            results.append({
                "id": ep.id,
                "subscription_id": ep.subscription_id,
                "subscription_title": ep.subscription.title if ep.subscription else None,
                "subscription_image_url": subscription_image_url,
                "title": ep.title,
                "description": ep.description,
                "audio_url": ep.audio_url,
                "audio_duration": ep.audio_duration,
                "audio_file_size": ep.audio_file_size,
                "published_at": ep.published_at,
                "image_url": image_url,
                "item_link": ep.item_link,
                "transcript_url": ep.transcript_url,
                "transcript_content": ep.transcript_content,
                "ai_summary": ep.ai_summary,
                "summary_version": ep.summary_version,
                "ai_confidence_score": ep.ai_confidence_score,
                "play_count": ep.play_count,
                "last_played_at": ep.last_played_at,
                "season": ep.season,
                "episode_number": ep.episode_number,
                "explicit": ep.explicit,
                "status": ep.status,
                "metadata": ep.metadata_json,
                # Playback state
                "current_position": playback.current_position if playback else None,
                "is_playing": playback.is_playing if playback else False,
                "playback_rate": playback.playback_rate if playback else 1.0,
                "is_played": is_played,
                "liked": playback.liked if playback else None,
                "created_at": ep.created_at,
                "updated_at": ep.updated_at,
            })

        return results

    def _rule_based_summary(self, title: str, content: str) -> str:
        """å¦‚æœæ²¡æœ‰LLMï¼Œä½¿ç”¨è§„åˆ™ç”ŸæˆåŸºæœ¬æ€»ç»“"""
        # å…³é”®è¯æå–
        import re

        # æå–å…³é”®å¥å­
        sentences = re.split(r'[.!?]', content)
        important_sentences = [
            s.strip()[:200] for s in sentences
            if any(keyword in s.lower() for keyword in ['key', 'main', 'conclusion', 'important', 'learn', 'feel'])
        ][:3]

        bullet_points = '\n'.join(f"â€¢ {s}" for s in important_sentences) if important_sentences else 'â€¢ ' + content[:150] + '...'
        disclaimer = "*ï¼ˆæ­¤ä¸ºå¿«é€Ÿæ€»ç»“ï¼Œå®é™…ä½¿ç”¨æ—¶å»ºè®®ç»‘å®šOpenAI APIï¼‰*"

        return f"""## æ’­å®¢æ€»ç»“

**èŠ‚ç›®**: {title}

{bullet_points}

{disclaimer}"""

    async def _wait_for_existing_summary(
        self,
        episode: PodcastEpisode,
        session: Optional[AsyncSession]
    ) -> str:
        """ç­‰å¾…ç°æœ‰çš„æ€»ç»“ä»»åŠ¡å®Œæˆ

        Args:
            episode: æ’­å®¢å•é›†å¯¹è±¡
            session: å¯é€‰çš„æ•°æ®åº“ä¼šè¯

        Returns:
            str: AIç”Ÿæˆçš„æ€»ç»“æ–‡æœ¬

        Raises:
            ValueError: å½“ç­‰å¾…è¶…æ—¶æ—¶
        """
        import asyncio
        from sqlalchemy import select

        logger.info(f"æ€»ç»“ä»»åŠ¡å·²åœ¨è¿›è¡Œä¸­: episode_id={episode.id}")
        current_try = 0
        while current_try < 5:
            await asyncio.sleep(2)
            if session:
                stmt = select(PodcastEpisode).where(PodcastEpisode.id == episode.id)
                result = await session.execute(stmt)
                episode_check = result.scalar_one_or_none()
            else:
                episode_check = await self.repo.get_episode_by_id(episode.id)

            if episode_check and episode_check.ai_summary:
                return episode_check.ai_summary
            current_try += 1

        raise ValueError("ç­‰å¾…æ€»ç»“è¶…æ—¶")

    def _prepare_episode_content(
        self,
        episode: PodcastEpisode
    ) -> Tuple[str, str, bool]:
        """å‡†å¤‡æ’­å®¢å•é›†å†…å®¹ç”¨äºæ€»ç»“

        Args:
            episode: æ’­å®¢å•é›†å¯¹è±¡

        Returns:
            Tuple[str, str, bool]: (åŸå§‹å†…å®¹, å†…å®¹ç±»å‹, æ˜¯å¦æœ‰è½¬å½•)
        """
        if episode.transcript_content:
            return episode.transcript_content, "transcript", True
        else:
            return episode.description, "description", False

    def _sanitize_content(
        self,
        raw_content: str,
        sanitizer: ContentSanitizer,
        content_type: str
    ) -> str:
        """å‡€åŒ–å†…å®¹å¹¶éªŒè¯

        Args:
            raw_content: åŸå§‹å†…å®¹
            sanitizer: å†…å®¹å‡€åŒ–å™¨
            content_type: å†…å®¹ç±»å‹æ ‡è¯†

        Returns:
            str: å‡€åŒ–åçš„å†…å®¹

        Raises:
            ValueError: å½“å†…å®¹å¤ªçŸ­æˆ–è¢«å®Œå…¨è¿‡æ»¤æ—¶
        """
        sanitized_prompt = sanitizer.sanitize(
            raw_content, self.user_id, f"podcast_{content_type}"
        )

        if not sanitized_prompt or len(sanitized_prompt.strip()) < 10:
            raise ValueError("å†…å®¹å¤ªçŸ­æˆ–å·²è¢«å®Œå…¨è¿‡æ»¤")

        return sanitized_prompt

    async def _get_episode_count(self, subscription_id: int) -> int:
        """è·å–è®¢é˜…çš„å•é›†æ•°é‡"""
        return await self.repo.count_subscription_episodes(subscription_id)

    async def _get_unplayed_count(self, subscription_id: int) -> int:
        """è·å–æœªæ’­æ”¾çš„å•é›†æ•°é‡"""
        episodes = await self.repo.get_subscription_episodes(subscription_id, limit=None)
        if not episodes:
            return 0

        # Batch fetch all playback states to avoid N+1 query problem
        episode_ids = [ep.id for ep in episodes]
        playback_states = await self.repo.get_playback_states_batch(self.user_id, episode_ids)

        unplayed = 0
        for ep in episodes:
            playback = playback_states.get(ep.id)
            if not playback or not playback.current_position or \
               (ep.audio_duration and playback.current_position < ep.audio_duration * 0.9):
                unplayed += 1

        return unplayed

    async def _calculate_listening_streak(self) -> int:
        """è®¡ç®—è¿ç»­æ”¶å¬å¤©æ•°"""
        # è·å–æœ€è¿‘30å¤©çš„æ’­æ”¾è®°å½•
        recent_plays = await self.repo.get_recent_play_dates(self.user_id, days=30)

        if not recent_plays:
            return 0

        # è®¡ç®—è¿ç»­å¤©æ•°
        streak = 1  # ä»Šå¤©
        from datetime import date, timedelta
        today = date.today()

        for i in range(1, 30):
            check_date = today - timedelta(days=i)
            if check_date in recent_plays:
                streak += 1
            else:
                break

        return streak

    # === è®¢é˜…åˆ é™¤è¾…åŠ©æ–¹æ³• ===

    async def _validate_and_get_subscription(
        self,
        subscription_id: int,
        check_source_type: bool = False
    ) -> Optional[Subscription]:
        """éªŒè¯è®¢é˜…å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·

        Args:
            subscription_id: è®¢é˜…ID
            check_source_type: æ˜¯å¦æ£€æŸ¥source_type

        Returns:
            Subscriptionå¯¹è±¡æˆ–None
        """
        from sqlalchemy import and_, select
        from app.domains.subscription.models import Subscription

        conditions = [
            Subscription.id == subscription_id,
            Subscription.user_id == self.user_id
        ]

        if check_source_type:
            conditions.append(Subscription.source_type == "podcast-rss")

        stmt = select(Subscription).where(and_(*conditions))
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()

    async def _get_episode_ids_for_subscription(
        self,
        subscription_id: int
    ) -> List[int]:
        """è·å–è®¢é˜…çš„æ‰€æœ‰episode_id

        Args:
            subscription_id: è®¢é˜…ID

        Returns:
            List[int]: episode_idåˆ—è¡¨
        """
        from sqlalchemy import select
        from app.domains.podcast.models import PodcastEpisode

        ep_stmt = select(PodcastEpisode.id).where(
            PodcastEpisode.subscription_id == subscription_id
        )
        ep_result = await self.db.execute(ep_stmt)
        return [row[0] for row in ep_result.fetchall()]

    async def _delete_subscription_related_entities(
        self,
        subscription_id: int,
        episode_ids: List[int]
    ) -> None:
        """åˆ é™¤è®¢é˜…ç›¸å…³çš„æ‰€æœ‰å®ä½“ï¼ˆæŒ‰å¤–é”®ä¾èµ–é¡ºåºï¼‰

        Args:
            subscription_id: è®¢é˜…ID
            episode_ids: è¦åˆ é™¤çš„episode_idåˆ—è¡¨
        """
        from sqlalchemy import delete
        from app.domains.podcast.models import (
            PodcastEpisode,
            PodcastPlaybackState,
            TranscriptionTask,
            PodcastConversation
        )
        from app.domains.subscription.models import Subscription

        # æŒ‰ä¾èµ–é¡ºåºåˆ é™¤ï¼šconversations -> playback -> transcriptions -> episodes -> subscription
        if episode_ids:
            await self.db.execute(
                delete(PodcastConversation).where(
                    PodcastConversation.episode_id.in_(episode_ids)
                )
            )
            await self.db.execute(
                delete(PodcastPlaybackState).where(
                    PodcastPlaybackState.episode_id.in_(episode_ids)
                )
            )
            await self.db.execute(
                delete(TranscriptionTask).where(
                    TranscriptionTask.episode_id.in_(episode_ids)
                )
            )

        await self.db.execute(
            delete(PodcastEpisode).where(
                PodcastEpisode.subscription_id == subscription_id
            )
        )
        await self.db.execute(
            delete(Subscription).where(
                Subscription.id == subscription_id
            )
        )

    # === æ‰¹é‡åˆ é™¤è®¢é˜… ===

    async def remove_subscriptions_bulk(
        self,
        subscription_ids: List[int]
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆ é™¤æ’­å®¢è®¢é˜…

        åˆ é™¤é¡ºåºï¼ˆæŒ‰å¤–é”®ä¾èµ–å…³ç³»ï¼‰:
        1. conversations (é€šè¿‡ episode_id)
        2. playback_progress (podcast_playback_states)
        3. transcriptions (transcription_tasks)
        4. episodes (podcast_episodes)
        5. subscriptions

        Args:
            subscription_ids: è¦åˆ é™¤çš„è®¢é˜…IDåˆ—è¡¨

        Returns:
            dict: {
                "success_count": int,
                "failed_count": int,
                "errors": List[Dict[str, Any]],
                "deleted_subscription_ids": List[int]
            }
        """
        success_count = 0
        failed_count = 0
        errors: List[Dict[str, Any]] = []
        deleted_subscription_ids: List[int] = []

        for subscription_id in subscription_ids:
            try:
                # ä½¿ç”¨æ˜¾å¼äº‹åŠ¡ç¡®ä¿åˆ é™¤æ“ä½œçš„åŸå­æ€§
                async with self.db.begin():
                    # 1. éªŒè¯è®¢é˜…å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
                    subscription = await self._validate_and_get_subscription(
                        subscription_id,
                        check_source_type=True
                    )

                    if not subscription:
                        errors.append({
                            "subscription_id": subscription_id,
                            "error": f"è®¢é˜… {subscription_id} ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                        })
                        failed_count += 1
                        continue

                    # 2. è·å–è¯¥è®¢é˜…çš„æ‰€æœ‰ episode_id
                    episode_ids = await self._get_episode_ids_for_subscription(subscription_id)

                    # 3. æŒ‰ä¾èµ–é¡ºåºåˆ é™¤æ‰€æœ‰ç›¸å…³å®ä½“
                    await self._delete_subscription_related_entities(subscription_id, episode_ids)

                # äº‹åŠ¡æäº¤æˆåŠŸï¼Œè®°å½•æˆåŠŸ
                success_count += 1
                deleted_subscription_ids.append(subscription_id)
                logger.info(f"ç”¨æˆ· {self.user_id} æ‰¹é‡åˆ é™¤è®¢é˜… {subscription_id} æˆåŠŸ")

            except Exception as e:
                # äº‹åŠ¡ä¼šè‡ªåŠ¨å›æ»š
                logger.error(f"æ‰¹é‡åˆ é™¤è®¢é˜… {subscription_id} å¤±è´¥: {e}")
                errors.append({
                    "subscription_id": subscription_id,
                    "error": str(e)
                })
                failed_count += 1

        return {
            "success_count": success_count,
            "failed_count": failed_count,
            "errors": errors,
            "deleted_subscription_ids": deleted_subscription_ids
        }
