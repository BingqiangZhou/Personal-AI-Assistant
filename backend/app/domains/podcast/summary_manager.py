"""
æ’­å®¢AIæ‘˜è¦æœåŠ¡ç®¡ç†å™¨
ä½¿ç”¨æ•°æ®åº“ä¸­çš„AIæ¨¡å‹é…ç½®
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Any, Optional

import aiohttp
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.exceptions import HTTPException, ValidationError
from app.domains.ai.models import ModelType
from app.domains.ai.repositories import AIModelConfigRepository
from app.domains.podcast.models import PodcastEpisode
from app.domains.subscription.parsers.feed_parser import strip_html_tags


logger = logging.getLogger(__name__)


class SummaryModelManager:
    """æ‘˜è¦æ¨¡å‹ç®¡ç†å™¨"""

    def __init__(self, db: AsyncSession):
        self.db = db
        self.ai_model_repo = AIModelConfigRepository(db)

    async def get_active_summary_model(self, model_name: Optional[str] = None):
        """è·å–æ´»è·ƒçš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹é…ç½®ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰"""
        if model_name:
            # æ ¹æ®åç§°è·å–æŒ‡å®šæ¨¡å‹
            model = await self.ai_model_repo.get_by_name(model_name)
            if not model or not model.is_active or model.model_type != ModelType.TEXT_GENERATION:
                raise ValidationError(f"Summary model '{model_name}' not found or not active")
            return model
        else:
            # æŒ‰ä¼˜å…ˆçº§è·å–æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åˆ—è¡¨
            active_models = await self.ai_model_repo.get_active_models_by_priority(ModelType.TEXT_GENERATION)
            if not active_models:
                raise ValidationError("No active summary model found")
            # è¿”å›ä¼˜å…ˆçº§æœ€é«˜çš„æ¨¡å‹ï¼ˆpriority æ•°å­—æœ€å°çš„ï¼‰
            return active_models[0]

    async def generate_summary(
        self,
        transcript: str,
        episode_info: dict[str, Any],
        model_name: Optional[str] = None,
        custom_prompt: Optional[str] = None
    ) -> dict[str, Any]:
        """
        ç”ŸæˆAIæ‘˜è¦ï¼ˆæ”¯æŒæ¨¡å‹fallbackæœºåˆ¶ï¼‰

        Args:
            transcript: è½¬å½•æ–‡æœ¬
            episode_info: æ’­å®¢å•é›†ä¿¡æ¯
            model_name: æŒ‡å®šçš„æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ‘˜è¦ç»“æœå­—å…¸

        Raises:
            ValidationError: å½“æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        # è·å–æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åˆ—è¡¨
        if model_name:
            # å¦‚æœæŒ‡å®šäº†æ¨¡å‹åç§°ï¼Œåªä½¿ç”¨è¯¥æ¨¡å‹
            model = await self.get_active_summary_model(model_name)
            models_to_try = [model]
        else:
            # è·å–æ‰€æœ‰æŒ‰ä¼˜å…ˆçº§æ’åºçš„æ´»è·ƒæ–‡æœ¬ç”Ÿæˆæ¨¡å‹
            models_to_try = await self.ai_model_repo.get_active_models_by_priority(ModelType.TEXT_GENERATION)
            if not models_to_try:
                raise ValidationError("No active text generation models available")

        last_error = None
        total_processing_time = 0
        total_tokens_used = 0

        # å°è¯•æ¯ä¸ªæ¨¡å‹ï¼ˆæŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
        for model_config in models_to_try:
            try:
                logger.info(f"Trying text generation model: {model_config.name} (priority: {model_config.priority})")

                # è§£å¯†APIå¯†é’¥
                api_key = await self._get_api_key(model_config)

                # æ„å»ºæç¤ºè¯
                if not custom_prompt:
                    custom_prompt = self._build_default_prompt(episode_info, transcript)

                # è°ƒç”¨AI APIç”Ÿæˆæ‘˜è¦ï¼ˆå¸¦é‡è¯•ï¼‰
                summary_content, processing_time, tokens_used = await self._call_ai_api_with_retry(
                    model_config=model_config,
                    api_key=api_key,
                    prompt=custom_prompt,
                    episode_info=episode_info
                )

                total_processing_time += processing_time
                total_tokens_used += tokens_used

                logger.info(f"Text generation succeeded with model: {model_config.name}")

                # æ›´æ–°æˆåŠŸç»Ÿè®¡ï¼ˆåªè®°å½•æœ€åä¸€æ¬¡æˆåŠŸçš„è°ƒç”¨ï¼Œå› ä¸ºé‡è¯•çš„å¤±è´¥å·²ç»åœ¨å†…éƒ¨è®°å½•äº†ï¼‰
                # å®é™…ä¸Šé‡è¯•çš„ç»Ÿè®¡å·²ç»åœ¨ _call_ai_api_with_retry ä¸­è®°å½•äº†ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤è®°å½•

                return {
                    "summary_content": summary_content,
                    "model_name": model_config.name,
                    "model_id": model_config.id,
                    "processing_time": total_processing_time,
                    "tokens_used": total_tokens_used
                }

            except Exception as e:
                last_error = e
                logger.warning(f"Text generation failed with model {model_config.name}: {str(e)}")
                # å¤±è´¥çš„ç»Ÿè®¡å·²ç»åœ¨ _call_ai_api_with_retry ä¸­è®°å½•äº†ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤è®°å½•
                continue

        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†
        error_msg = f"All text generation models failed. Last error: {str(last_error)}"
        logger.error(error_msg)
        raise ValidationError(error_msg)

    async def _call_ai_api_with_retry(
        self,
        model_config,
        api_key: str,
        prompt: str,
        episode_info: dict[str, Any]
    ) -> tuple[str, float, int]:
        """
        è°ƒç”¨AI APIç”Ÿæˆæ‘˜è¦ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            model_config: æ¨¡å‹é…ç½®
            api_key: APIå¯†é’¥
            prompt: æç¤ºè¯
            episode_info: æ’­å®¢å•é›†ä¿¡æ¯

        Returns:
            Tuple[æ‘˜è¦å†…å®¹, å¤„ç†æ—¶é—´(ç§’), ä½¿ç”¨çš„tokenæ•°]

        Raises:
            Exception: å½“æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        max_retries = 3
        base_delay = 2  # seconds

        for attempt in range(max_retries):
            attempt_start = time.time()
            try:
                logger.info(f"ğŸ“ [SUMMARY] Attempt {attempt+1}/{max_retries} with model {model_config.name}")

                # è°ƒç”¨API
                summary_content = await self._call_ai_api(
                    model_config=model_config,
                    api_key=api_key,
                    prompt=prompt,
                    episode_info=episode_info
                )

                processing_time = time.time() - attempt_start
                tokens_used = len(prompt.split()) + len(summary_content.split())

                # è®°å½•æœ¬æ¬¡å°è¯•æˆåŠŸ
                await self.ai_model_repo.increment_usage(
                    model_config.id,
                    success=True,
                    tokens_used=tokens_used
                )
                logger.debug(f"ğŸ“Š [STATS] Recorded success for model {model_config.name}, attempt {attempt+1}")

                return summary_content, processing_time, tokens_used

            except Exception as e:
                processing_time = time.time() - attempt_start
                logger.error(f"âŒ [SUMMARY] Attempt {attempt+1} failed for model {model_config.name}: {str(e)}")

                # è®°å½•æœ¬æ¬¡å°è¯•å¤±è´¥
                await self.ai_model_repo.increment_usage(
                    model_config.id,
                    success=False
                )
                logger.debug(f"ğŸ“Š [STATS] Recorded failure for model {model_config.name}, attempt {attempt+1}")

                if attempt < max_retries - 1:
                    delay = base_delay * (2 ** attempt)
                    logger.info(f"â³ [SUMMARY] Retrying in {delay}s...")
                    await asyncio.sleep(delay)
                else:
                    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise Exception(f"Model {model_config.name} failed after {max_retries} attempts: {str(e)}")

        # ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
        raise Exception("Unexpected error in _call_ai_api_with_retry")

    async def _call_ai_api(
        self,
        model_config,
        api_key: str,
        prompt: str,
        episode_info: dict[str, Any]
    ) -> str:
        """è°ƒç”¨AI APIç”Ÿæˆæ‘˜è¦"""
        # æ£€æŸ¥å¹¶å¤„ç†è¿‡é•¿çš„è½¬å½•æ–‡æœ¬
        max_prompt_length = 100000  # çº¦ 25k tokens
        if len(prompt) > max_prompt_length:
            logger.warning(f"Prompt too long ({len(prompt)} chars), truncating to {max_prompt_length} chars")
            prompt = prompt[:max_prompt_length] + "\n\n[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­]"

        # æ„å»º API URL - é¿å…è·¯å¾„é‡å¤
        api_url = model_config.api_url
        if not api_url.endswith('/chat/completions'):
            # å¦‚æœ URL ä¸åŒ…å«å®Œæ•´è·¯å¾„ï¼Œåˆ™æ·»åŠ 
            if api_url.endswith('/'):
                api_url = f"{api_url}chat/completions"
            else:
                api_url = f"{api_url}/chat/completions"

        timeout = aiohttp.ClientTimeout(total=model_config.timeout_seconds)

        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }

        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            'model': model_config.model_id,
            'messages': [
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'temperature': model_config.get_temperature_float() or 0.7
        }

        # Only include max_tokens if it's set (some APIs don't accept null)
        if model_config.max_tokens is not None:
            data['max_tokens'] = model_config.max_tokens

        # æ·»åŠ é¢å¤–é…ç½®
        if model_config.extra_config:
            data.update(model_config.extra_config)

        # è¯¦ç»†æ—¥å¿—è®°å½•
        logger.info(f"ğŸ¤– [AI API] Calling {model_config.provider} API:")
        logger.info(f"  - URL: {api_url}")
        logger.info(f"  - Model: {model_config.model_id}")
        logger.info(f"  - Prompt length: {len(prompt)} chars")
        logger.info(f"  - Max tokens: {model_config.max_tokens}")
        logger.info(f"  - Temperature: {data.get('temperature')}")

        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(api_url, headers=headers, json=data) as response:
                if response.status != 200:
                    error_text = await response.text()
                    logger.error("âŒ [AI API] Request failed:")
                    logger.error(f"  - Status: {response.status}")
                    logger.error(f"  - Error: {error_text}")
                    logger.error(f"  - Request data keys: {list(data.keys())}")
                    logger.error(f"  - Headers: {headers}")

                    # æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
                    if response.status == 400:
                        raise HTTPException(
                            status_code=500,
                            detail=f"AI API bad request (400). Possible causes: invalid model ID, malformed request, or prompt too long. Error: {error_text[:200]}"
                        )
                    elif response.status == 401:
                        raise HTTPException(
                            status_code=500,
                            detail="AI API authentication failed (401). Check API key configuration."
                        )
                    else:
                        raise HTTPException(
                            status_code=500,
                            detail=f"AI summary API error: {response.status} - {error_text[:200]}"
                        )

                result = await response.json()

                if 'choices' not in result or not result['choices']:
                    logger.error(f"âŒ [AI API] Invalid response structure: {result}")
                    raise HTTPException(
                        status_code=500,
                        detail="Invalid response from AI API"
                    )

                content = result['choices'][0].get('message', {}).get('content')
                if not content or not isinstance(content, str):
                    logger.error(f"âŒ [AI API] Returned invalid content: {result}")
                    raise HTTPException(
                        status_code=500,
                        detail="AI API returned empty or invalid content"
                    )

                # Filter out <thinking> tags and content
                # è¿‡æ»¤æ‰ <thinking> æ ‡ç­¾åŠå…¶å†…å®¹
                from app.core.utils import filter_thinking_content
                original_length = len(content)
                cleaned_content = filter_thinking_content(content)

                if len(cleaned_content) != original_length:
                    logger.info(f"ğŸ§¹ [FILTER] Removed thinking content: {original_length} -> {len(cleaned_content)} chars")

                logger.info(f"âœ… [AI API] Summary generated successfully: {len(cleaned_content)} chars")
                return cleaned_content.strip()

    def _build_default_prompt(self, episode_info: dict[str, Any], transcript: str) -> str:
        """æ„å»ºé»˜è®¤çš„æ‘˜è¦æç¤ºè¯"""
        title = episode_info.get('title', 'æœªçŸ¥æ ‡é¢˜')
        raw_description = episode_info.get('description', '')

        # å‰¥ç¦»HTMLæ ‡ç­¾ï¼Œç¡®ä¿AIåªçœ‹åˆ°çº¯æ–‡æœ¬å†…å®¹
        description = strip_html_tags(raw_description)

        prompt = f"""# Role
ä½ æ˜¯ä¸€ä½è¿½æ±‚æè‡´å®Œæ•´æ€§çš„èµ„æ·±æ’­å®¢å†…å®¹åˆ†æå¸ˆã€‚ä½ çš„ç›®æ ‡æ˜¯å°†å†—é•¿çš„éŸ³é¢‘è½¬å½•æ–‡æœ¬è½¬åŒ–ä¸ºä¸€ä»½è¯¦å°½ã€ç»“æ„åŒ–ä¸”**ææ˜“é˜…è¯»**çš„æ·±åº¦ç ”æŠ¥ã€‚

# Task
è¯·æ ¹æ®æä¾›çš„å…ƒæ•°æ®å’Œè½¬å½•æ–‡æœ¬ç”Ÿæˆæ€»ç»“ã€‚
**æ ¸å¿ƒåŸåˆ™**ï¼š
1. **å®Œæ•´æ€§**ï¼šå†…å®¹å®Œæ•´æ€§é«˜äºç¯‡å¹…é™åˆ¶ï¼Œä¸è¦å—é™äºå›ºå®šçš„æ®µè½æ•°é‡ã€‚
2. **å¯è¯»æ€§**ï¼š**ä¸¥ç¦ä½¿ç”¨å¤§æ®µè½çº¯æ–‡æœ¬ï¼ˆWall of Textï¼‰**ã€‚æ‰€æœ‰ä¿¡æ¯å¿…é¡»é€šè¿‡"æ ‡é¢˜ + åˆ—è¡¨"çš„å½¢å¼å‘ˆç°ï¼Œç¡®ä¿ç”¨æˆ·å¯ä»¥å¿«é€Ÿæ‰«ææ ¸å¿ƒä¿¡æ¯ã€‚

# Input Data
<podcast_info>
Title: {title}
Shownotes: {description}
</podcast_info>

<transcript>
{transcript}
</transcript>

# Analysis Constraints
1. **å…¨é¢è¦†ç›–**ï¼šä¸è¦é—æ¼ä»»ä½•ä¸€ä¸ªä¸»è¦è¯é¢˜ã€‚å¦‚æœæ’­å®¢è®¨è®ºäº† 10 ä¸ªä¸åŒçš„è¯é¢˜ï¼Œè¯·ç”Ÿæˆ 10 ä¸ªå¯¹åº”çš„å°èŠ‚ã€‚
2. **äº‹å®æ¥æºä¸¥æ ¼åˆ†çº§**ï¼š
    - **æœ€é«˜ä¼˜å…ˆçº§**ï¼š<transcript>ã€‚æ‰€æœ‰çš„è§‚ç‚¹ã€æ•°æ®ã€ç»“è®ºå¿…é¡»ä¸¥æ ¼æºè‡ªå®é™…çš„å¯¹è¯è½¬å½•ã€‚
    - **è¾…åŠ©å‚è€ƒ**ï¼š<podcast_info> (Shownotes)ã€‚ä»…ç”¨äºæå–æ­£ç¡®çš„äººåæ‹¼å†™ã€ä¸“ä¸šæœ¯è¯­ã€‚
    - **å†²çªå¤„ç†**ï¼šå¦‚æœ Shownotes å†…å®¹åœ¨ Transcript ä¸­æœªå‡ºç°ï¼Œ**åšå†³ä¸å†™å…¥æ€»ç»“**ã€‚
3. **è§†è§‰å±‚çº§**ï¼šè¿™æ˜¯ä¸ºäº†è§£å†³"é˜…è¯»ä¸ä¾¿"çš„é—®é¢˜ã€‚
    - **å¤šç”¨åˆ—è¡¨**ï¼šä¸»è¦å†…å®¹å¿…é¡»ä½¿ç”¨æ— åºåˆ—è¡¨ï¼ˆ- ï¼‰æˆ–æœ‰åºåˆ—è¡¨ï¼ˆ1. ï¼‰å‘ˆç°ã€‚
    - **åŠ ç²—å…³é”®**ï¼šå¯¹äººåã€å·¥å…·åã€æ ¸å¿ƒæ•°æ®ã€å…³é”®ç»“è®ºè¿›è¡Œ**åŠ ç²—**å¤„ç†ã€‚

# Output Structure (Strictly Follow)

## 1. ä¸€å¥è¯æ‘˜è¦ (Executive Summary)
ç”¨ç²¾ç‚¼çš„è¯­è¨€ï¼ˆ50-100å­—ï¼‰æ¦‚æ‹¬æ•´æœŸæ’­å®¢çš„æ ¸å¿ƒä¸»æ—¨ã€‚

## 2. æ ¸å¿ƒè§‚ç‚¹ä¸æ´å¯Ÿ (Key Insights & Takeaways)
æå–æœ¬æœŸæ’­å®¢ä¸­æ‰€æœ‰å…·æœ‰ç‹¬ç«‹ä»·å€¼çš„è§‚ç‚¹ã€‚
- **æ•°é‡ä¸é™**ï¼šåŠ¡å¿…è¦†ç›–æ‰€æœ‰å…³é”®ç»“è®ºã€‚
- **æ ¼å¼è¦æ±‚**ï¼šä½¿ç”¨åˆ—è¡¨å½¢å¼ã€‚
    - **[è§‚ç‚¹å…³é”®è¯]**ï¼šè¯¦ç»†é˜è¿°ã€‚
- **é€»è¾‘åˆ†ç»„**ï¼šå¦‚æœè§‚ç‚¹è¾ƒå¤šï¼Œè¯·ä½¿ç”¨**ä¸‰çº§æ ‡é¢˜ï¼ˆ###ï¼‰**è¿›è¡Œåˆ†ç±»ï¼ˆä¾‹å¦‚ï¼š### å¸‚åœºè¶‹åŠ¿ã€### æŠ€æœ¯å®ç°ï¼‰ï¼Œæ¯ä¸€ç±»ä¸‹é¢å†åˆ—å‡ºå…·ä½“è§‚ç‚¹ã€‚

## 3. å†…å®¹æ·±åº¦æ‹†è§£ (Deep Dive / Topic Breakdown)
**è¿™æ˜¯æœ¬æ€»ç»“æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ã€‚** è¯·é¡ºç€å¯¹è¯çš„æ—¶é—´çº¿æˆ–é€»è¾‘æµï¼Œå°†é•¿æ–‡æœ¬è‡ªç„¶æ‹†è§£ä¸ºå¤šä¸ªæ¿å—ã€‚

**ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘**ï¼šåœ¨æ­¤éƒ¨åˆ†ï¼Œ**ç¦æ­¢ä½¿ç”¨è‡ªç„¶æ®µè½å†™ä½œ**ã€‚å¿…é¡»ä½¿ç”¨**"å°æ ‡é¢˜ + åµŒå¥—åˆ—è¡¨"**çš„ç»“æ„ã€‚

- **åˆ‡åˆ†åŸåˆ™**ï¼šæ¯å½“å¯¹è¯åˆ‡æ¢åˆ°ä¸€ä¸ªæ–°çš„é‡å¤§è¯é¢˜æˆ–è®®ç¨‹æ—¶ï¼Œå°±åˆ›å»ºä¸€ä¸ªæ–°çš„**ä¸‰çº§æ ‡é¢˜**ï¼ˆä¾‹å¦‚ï¼š### 3.1 è¯é¢˜ï¼š...ï¼‰ã€‚
- **å†…å®¹å‘ˆç°æ–¹å¼**ï¼š
    - ä½¿ç”¨ **æ— åºåˆ—è¡¨** ç½—åˆ—è¯¥è¯é¢˜ä¸‹çš„æ ¸å¿ƒè®ºç‚¹ã€‚
    - åœ¨è®ºç‚¹ä¹‹ä¸‹ï¼Œä½¿ç”¨ **ç¼©è¿›åˆ—è¡¨** è¡¥å……å…·ä½“çš„è®ºæ®ã€æ•°æ®ã€æ¡ˆä¾‹æˆ–æ­£åæ–¹è§‚ç‚¹ã€‚
    - **äººå/å·¥å…·/æ•°æ®**ï¼šå¿…é¡»**åŠ ç²—**æ˜¾ç¤ºã€‚
    - **ç¤ºä¾‹ç»“æ„**ï¼š
        * **æ ¸å¿ƒè®ºç‚¹ A**
            * ç»†èŠ‚è§£é‡Šï¼š...
            * æåˆ°çš„æ¡ˆä¾‹ï¼š**æŸæŸå…¬å¸**çš„ä¾‹å­...
        * **æ ¸å¿ƒè®ºç‚¹ B**
            * å˜‰å®¾ **[åå­—]** æå‡ºçš„åå¯¹æ„è§ï¼š...
            * ç›¸å…³æ•°æ®ï¼šå¢é•¿äº† **40%**...

## 4. ç²¾å½©è¯­å½•ä¸é‡‘å¥ (Memorable Quotes)
æ‘˜å½•åŸæ–‡ä¸­æ‰€æœ‰æ‰“åŠ¨äººå¿ƒã€å‘äººæ·±çœæˆ–å…·æœ‰å¹½é»˜æ„Ÿçš„åŸè¯ã€‚
- **æ ¼å¼è¦æ±‚**ï¼šä½¿ç”¨åˆ—è¡¨å½¢å¼ã€‚
- **è¦æ±‚**ï¼šæ³¨æ˜è¯´è¯äººï¼ˆå¦‚æœæœ‰ï¼‰å’Œç®€çŸ­èƒŒæ™¯ã€‚

## 5. é€‚åˆå¬ä¼—ä¸æ”¶è· (Audience & Value)
ç®€è¦è¯´æ˜æœ¬æœŸå†…å®¹é€‚åˆå“ªç±»äººç¾¤æ·±å…¥è†å¬ï¼Œä»¥åŠä»–ä»¬èƒ½ä»ä¸­å­¦åˆ°ä»€ä¹ˆã€‚

# Start Analysis
è¯·å¼€å§‹è¿›è¡Œè¯¦å°½çš„åˆ†æï¼Œç¡®ä¿æ‰€æœ‰å†…å®¹"æ¡ç†åŒ–"ã€"åˆ—è¡¨åŒ–"ï¼Œä¸¥æ ¼éµå®ˆäº‹å®åˆ†çº§åŸåˆ™ï¼š
"""
        return prompt

    async def _get_api_key(self, model_config) -> str:
        """è·å–APIå¯†é’¥ï¼ˆç»Ÿä¸€ä»æ•°æ®åº“è¯»å–ï¼Œæ”¯æŒåå¤‡æŸ¥æ‰¾ï¼‰"""
        # Placeholders that indicate invalid API keys
        invalid_api_keys = {
            'your-openai-api-key-here',
            'your-api-key-here',
            '',
            'none',
            'null',
            'your-ope************here',  # Partial match from error logs
        }

        def is_invalid_key(key: str) -> bool:
            """Check if API key is invalid/placeholder"""
            if not key:
                return True
            key_lower = key.lower().strip()
            # Check against known placeholders (skip empty strings to avoid false positives)
            for placeholder in invalid_api_keys:
                if not placeholder:
                    continue  # Skip empty placeholders
                placeholder_lower = placeholder.lower()
                if key_lower == placeholder_lower or placeholder_lower in key_lower:
                    return True
            # Check for common placeholder patterns
            if 'your-' in key_lower and ('key' in key_lower or 'api' in key_lower):
                return True
            return False

        # Helper to get and validate API key from a model
        async def get_valid_key_from_model(model) -> Optional[str]:
            if not model or not model.api_key:
                return None

            key = model.api_key
            if not model.api_key_encrypted:
                if is_invalid_key(key):
                    return None
                return key

            # Decrypt if encrypted
            from app.core.security import decrypt_data
            try:
                decrypted = decrypt_data(model.api_key)
                if is_invalid_key(decrypted):
                    return None
                return decrypted
            except Exception as e:
                logger.error(f"Failed to decrypt API key for model {model.name}: {e}")
                return None

        # First try to get API key from the provided model_config
        api_key = await get_valid_key_from_model(model_config)
        if api_key:
            logger.info(f"Using API key from model {model_config.name}")
            return api_key

        # If current model has invalid key, try to find another active model with valid key
        logger.warning(f"Model {model_config.name} has invalid or placeholder API key, searching for alternative...")

        active_models = await self.ai_model_repo.get_active_models(ModelType.TEXT_GENERATION)
        for model in active_models:
            if model.id == model_config.id:
                continue  # Skip the same model
            alt_key = await get_valid_key_from_model(model)
            if alt_key:
                logger.info(f"Found valid API key from alternative model: {model.name}")
                return alt_key

        # No valid API key found
        raise ValidationError(
            f"No valid API key found. Model '{model_config.name}' has a placeholder/invalid API key, "
            f"and no alternative models with valid API keys were found. "
            f"Please configure a valid API key for at least one TEXT_GENERATION model."
        )

    async def get_model_info(self, model_name: Optional[str] = None) -> dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        model_config = await self.get_active_summary_model(model_name)
        return {
            "model_id": model_config.id,
            "name": model_config.name,
            "display_name": model_config.display_name,
            "provider": model_config.provider,
            "model_id_str": model_config.model_id,
            "max_tokens": model_config.max_tokens,
            "temperature": model_config.temperature,
            "timeout_seconds": model_config.timeout_seconds,
            "extra_config": model_config.extra_config or {}
        }

    async def list_available_models(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ‘˜è¦æ¨¡å‹"""
        active_models = await self.ai_model_repo.get_active_models(ModelType.TEXT_GENERATION)
        return [
            {
                "id": model.id,
                "name": model.name,
                "display_name": model.display_name,
                "provider": model.provider,
                "model_id": model.model_id,
                "is_default": model.is_default
            }
            for model in active_models
        ]


class DatabaseBackedAISummaryService:
    """åŸºäºæ•°æ®åº“é…ç½®çš„AIæ‘˜è¦æœåŠ¡"""

    def __init__(self, db: AsyncSession):
        self.db = db
        self.model_manager = SummaryModelManager(db)

    async def generate_summary(
        self,
        episode_id: int,
        model_name: Optional[str] = None,
        custom_prompt: Optional[str] = None
    ) -> dict[str, Any]:
        """ä¸ºæ’­å®¢å•é›†ç”ŸæˆAIæ‘˜è¦"""
        # è·å–æ’­å®¢å•é›†ä¿¡æ¯
        from sqlalchemy import select
        stmt = select(PodcastEpisode).where(PodcastEpisode.id == episode_id)
        result = await self.db.execute(stmt)
        episode = result.scalar_one_or_none()

        if not episode:
            raise ValidationError(f"Episode {episode_id} not found")

        # è·å–è½¬å½•å†…å®¹
        transcript_content = episode.transcript_content
        if not transcript_content:
            raise ValidationError(f"No transcript content available for episode {episode_id}")

        # æ„å»ºæ’­å®¢ä¿¡æ¯
        episode_info = {
            "title": episode.title,
            "description": episode.description,
            "duration": episode.audio_duration
        }

        # ç”Ÿæˆæ‘˜è¦
        summary_result = await self.model_manager.generate_summary(
            transcript=transcript_content,
            episode_info=episode_info,
            model_name=model_name,
            custom_prompt=custom_prompt
        )

        # æ›´æ–°æ•°æ®åº“ä¸­çš„æ‘˜è¦ä¿¡æ¯
        await self._update_episode_summary(episode_id, summary_result)

        return summary_result

    async def _update_episode_summary(self, episode_id: int, summary_result: dict[str, Any]):
        """æ›´æ–°æ’­å®¢å•é›†çš„æ‘˜è¦ä¿¡æ¯"""
        import logging
        logger = logging.getLogger(__name__)
        from sqlalchemy import update

        try:
            # è·å–æ€»ç»“å†…å®¹å’Œç›¸å…³ä¿¡æ¯
            summary_content = summary_result["summary_content"]
            model_name = summary_result["model_name"]
            processing_time = summary_result["processing_time"]
            
            # å­—æ®µé•¿åº¦æ£€æŸ¥å’Œå¤„ç†
            max_summary_length = 100000  # è®¾ç½®åˆç†çš„æœ€å¤§é•¿åº¦é™åˆ¶
            original_length = len(summary_content)
            
            if original_length > max_summary_length:
                logger.warning(f"Summary content too long ({original_length} chars), truncating to {max_summary_length} chars")
                summary_content = summary_content[:max_summary_length] + "..."
            
            # è®¡ç®—å­—æ•°
            word_count = len(summary_content.split())
            
            logger.info(f"Updating summary for episode {episode_id}: {word_count} words, model: {model_name}")
            logger.debug(f"Summary content: {summary_content[:100]}...")

            # æ›´æ–°æ’­å®¢å•é›†è¡¨
            stmt = (
                update(PodcastEpisode)
                .where(PodcastEpisode.id == episode_id)
                .values(
                    ai_summary=summary_content,
                    summary_version="1.0",
                    updated_at=datetime.utcnow()
                )
            )
            logger.debug(f"Executing update on podcast_episodes table for episode {episode_id}")
            result = await self.db.execute(stmt)
            logger.debug(f"Update result on podcast_episodes: {result.rowcount} rows affected")

            # æ›´æ–°è½¬å½•ä»»åŠ¡è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            from app.domains.podcast.models import TranscriptionTask
            stmt = (
                update(TranscriptionTask)
                .where(TranscriptionTask.episode_id == episode_id)
                .values(
                    summary_content=summary_content,
                    summary_model_used=model_name,
                    summary_word_count=word_count,
                    summary_processing_time=processing_time,
                    summary_error_message=None,
                    updated_at=datetime.utcnow()
                )
            )
            logger.debug(f"Executing update on transcription_tasks table for episode {episode_id}")
            result = await self.db.execute(stmt)
            logger.debug(f"Update result on transcription_tasks: {result.rowcount} rows affected")

            logger.debug(f"Committing transaction for episode {episode_id}")
            await self.db.commit()
            logger.info(f"Successfully updated summary for episode {episode_id}")
            
        except Exception as e:
            logger.error(f"Failed to update summary for episode {episode_id}: {str(e)}")
            logger.exception("Exception details:")
            try:
                # å°è¯•å›æ»šäº‹åŠ¡
                await self.db.rollback()
                logger.debug(f"Transaction rolled back for episode {episode_id}")
            except Exception as rollback_error:
                logger.error(f"Failed to rollback transaction for episode {episode_id}: {str(rollback_error)}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†
            raise

    async def regenerate_summary(
        self,
        episode_id: int,
        model_name: Optional[str] = None,
        custom_prompt: Optional[str] = None
    ) -> dict[str, Any]:
        """é‡æ–°ç”ŸæˆAIæ‘˜è¦"""
        return await self.generate_summary(episode_id, model_name, custom_prompt)

    async def get_summary_models(self):
        """è·å–å¯ç”¨çš„æ‘˜è¦æ¨¡å‹åˆ—è¡¨"""
        return await self.model_manager.list_available_models()
