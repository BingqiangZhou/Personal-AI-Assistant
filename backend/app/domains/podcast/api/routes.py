"""
æ’­å®¢APIè·¯ç”± - /api/v1/podcasts/*

ç»ˆç«¯è·¯ç”±:
POST   /podcasts/subscription           æ·»åŠ æ’­å®¢è®¢é˜…
GET    /podcasts/subscription           åˆ—å‡ºæ‰€æœ‰è®¢é˜…
GET    /podcasts/subscription/{id}      è·å–è®¢é˜…è¯¦æƒ…
DELETE /podcasts/subscription/{id}      åˆ é™¤è®¢é˜…

GET    /podcasts/episodes/feed          è·å–æ’­å®¢ä¿¡æ¯æµ
GET    /podcasts/episodes               è·å–å•é›†åˆ—è¡¨
GET    /podcasts/episodes/{id}          è·å–å•é›†è¯¦æƒ…
POST   /podcasts/episodes/{id}/summary  è§¦å‘AIæ€»ç»“
POST   /podcasts/episodes/{id}/progress æ›´æ–°æ’­æ”¾è¿›åº¦

GET    /podcasts/summary/pending        å¾…æ€»ç»“åˆ—è¡¨
"""

import logging
from datetime import datetime
from typing import Optional

from fastapi import APIRouter, Body, Depends, HTTPException, Query, Request, status
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_db_session
from app.core.etag_response import ETagResponse, check_etag_precondition
from app.core.security import get_token_from_request
from app.domains.podcast.models import PodcastEpisode, TranscriptionStatus
from app.domains.podcast.services import PodcastService
from app.domains.podcast.summary_manager import DatabaseBackedAISummaryService
from app.domains.podcast.transcription_manager import DatabaseBackedTranscriptionService
from app.domains.podcast.transcription_state import get_transcription_state_manager


logger = logging.getLogger(__name__)
from app.domains.podcast.schemas import (
    PodcastConversationClearResponse,
    PodcastConversationHistoryResponse,
    PodcastConversationMessage,
    PodcastConversationSendRequest,
    PodcastConversationSendResponse,
    PodcastEpisodeDetailResponse,
    PodcastEpisodeFilter,
    PodcastEpisodeListResponse,
    PodcastEpisodeResponse,
    PodcastFeedResponse,
    PodcastPlaybackStateResponse,
    PodcastPlaybackUpdate,
    PodcastSearchFilter,
    PodcastStatsResponse,
    PodcastSubscriptionBatchResponse,
    PodcastSubscriptionBulkDelete,
    PodcastSubscriptionBulkDeleteResponse,
    PodcastSubscriptionCreate,
    PodcastSubscriptionListResponse,
    PodcastSubscriptionResponse,
    PodcastSummaryPendingResponse,
    PodcastSummaryRequest,
    PodcastSummaryResponse,
    PodcastTranscriptionDetailResponse,
    PodcastTranscriptionRequest,
    PodcastTranscriptionResponse,
    PodcastTranscriptionStatusResponse,
    ScheduleConfigResponse,
    ScheduleConfigUpdate,
    SummaryModelInfo,
    SummaryModelsResponse,
)
from app.domains.podcast.transcription_scheduler import (
    ScheduleFrequency,
    TranscriptionScheduler,
    batch_transcribe_subscription,
    get_episode_transcript,
)


router = APIRouter(prefix="")

logger = logging.getLogger(__name__)


# === Transcription helper functions ===

async def _validate_episode_and_permission(
    episode_id: int,
    user_id: int,
    service: PodcastService
) -> PodcastEpisode:
    """éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·

    Args:
        episode_id: å•é›†ID
        user_id: ç”¨æˆ·ID
        service: PodcastServiceå®ä¾‹

    Returns:
        PodcastEpisodeå¯¹è±¡

    Raises:
        HTTPException: å½“å•é›†ä¸å­˜åœ¨æˆ–æ— æƒé™æ—¶

    Note: Ownership is verified by the repository layer via UserSubscription join.
    """
    episode = await service.get_episode_by_id(episode_id, user_id=user_id)
    if not episode:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Episode {episode_id} not found"
        )

    return episode


async def _check_redis_cached_task(
    episode_id: int,
    state_manager,
    transcription_service: DatabaseBackedTranscriptionService,
    episode: PodcastEpisode
) -> Optional[PodcastTranscriptionResponse]:
    """æ£€æŸ¥Redisç¼“å­˜ä¸­çš„ä»»åŠ¡

    Args:
        episode_id: å•é›†ID
        state_manager: çŠ¶æ€ç®¡ç†å™¨
        transcription_service: è½¬å½•æœåŠ¡
        episode: æ’­å®¢å•é›†å¯¹è±¡

    Returns:
        å¦‚æœæœ‰ç¼“å­˜ä»»åŠ¡åˆ™è¿”å›å“åº”ï¼Œå¦åˆ™è¿”å›None
    """
    redis_task_id = await state_manager.get_episode_task(episode_id)
    if redis_task_id:
        cached_progress = await state_manager.get_task_progress(redis_task_id)
        if cached_progress and cached_progress.get("status") not in ["completed", "failed"]:
            logger.info(f"âš¡ [REDIS] Returning cached in-progress task {redis_task_id} for episode {episode_id}")
            task = await transcription_service.get_transcription_status(redis_task_id)
            if task:
                return _build_transcription_response(task, episode)
    return None


async def _check_existing_db_task(
    episode_id: int,
    force_regenerate: bool,
    transcription_service: DatabaseBackedTranscriptionService,
    episode: PodcastEpisode
) -> Optional[PodcastTranscriptionResponse]:
    """æ£€æŸ¥æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„ä»»åŠ¡

    Args:
        episode_id: å•é›†ID
        force_regenerate: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆ
        transcription_service: è½¬å½•æœåŠ¡
        episode: æ’­å®¢å•é›†å¯¹è±¡

    Returns:
        å¦‚æœæœ‰ç°æœ‰ä»»åŠ¡åˆ™è¿”å›å“åº”ï¼Œå¦åˆ™è¿”å›None
    """
    existing_task = await transcription_service.get_episode_transcription(episode_id)
    if existing_task:
        if existing_task.status == 'completed' and not force_regenerate:
            logger.info(f"âœ… [DB] Returning existing completed task {existing_task.id} for episode {episode_id}")
            return _build_transcription_response(existing_task, episode)
        elif existing_task.status == 'in_progress' and not force_regenerate:
            state_manager = await get_transcription_state_manager()
            await state_manager.set_episode_task(episode_id, existing_task.id)
            logger.info(f"ğŸ”„ [DB] Returning existing in-progress task {existing_task.id} for episode {episode_id}")
            return _build_transcription_response(existing_task, episode)
    return None


# === è®¢é˜…ç®¡ç† ===

@router.post(
    "/subscriptions",
    status_code=status.HTTP_201_CREATED,
    response_model=PodcastSubscriptionResponse,
    summary="æ·»åŠ æ’­å®¢è®¢é˜…",
    description="é€šè¿‡RSSé“¾æ¥æ·»åŠ æ’­å®¢è®¢é˜…ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆå‰å‡ æœŸéŸ³é¢‘çš„AIæ€»ç»“"
)
async def add_subscription(
    subscription_data: PodcastSubscriptionCreate,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "feed_url": "https://feeds.soundcloud.com/users/soundcloud:users:123456/tracks.rss",
        "custom_name": "æˆ‘çš„æ’­å®¢",
        "category_ids": [1, 2]
    }
    ```
    """
    service = PodcastService(db, int(user["sub"]))
    try:
        subscription, new_episodes = await service.add_subscription(
            feed_url=subscription_data.feed_url,
            category_ids=subscription_data.category_ids
        )

        # è½¬æ¢ä¸ºå“åº”æ¨¡å‹
        response_data = {
            "id": subscription.id,
            "title": subscription.title,
            "description": subscription.description,
            "source_url": subscription.source_url,
            "status": subscription.status,
            "last_fetched_at": subscription.last_fetched_at,
            "error_message": subscription.error_message,
            "fetch_interval": subscription.fetch_interval,
            "episode_count": len(new_episodes),
            "unplayed_count": len(new_episodes),
            "created_at": subscription.created_at,
            "updated_at": subscription.updated_at
        }

        return PodcastSubscriptionResponse(**response_data)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ·»åŠ è®¢é˜…å¤±è´¥: {str(e)}")


@router.post(
    "/subscriptions/bulk",
    response_model=PodcastSubscriptionBatchResponse,
    summary="æ‰¹é‡æ·»åŠ æ’­å®¢è®¢é˜…"
)
async def create_subscriptions_batch(
    subscriptions_data: list[PodcastSubscriptionCreate],
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """æ‰¹é‡æ·»åŠ æ’­å®¢è®¢é˜…"""
    service = PodcastService(db, int(user["sub"]))
    results = await service.add_subscriptions_batch(subscriptions_data)
    
    success_count = sum(1 for r in results if r["status"] == "success")
    skipped_count = sum(1 for r in results if r["status"] == "skipped")
    error_count = sum(1 for r in results if r["status"] == "error")
    
    return PodcastSubscriptionBatchResponse(
        results=results,
        total_requested=len(subscriptions_data),
        success_count=success_count,
        skipped_count=skipped_count,
        error_count=error_count
    )


@router.get(
    "/subscriptions",
    response_model=PodcastSubscriptionListResponse,
    summary="åˆ—å‡ºæ‰€æœ‰æ’­å®¢è®¢é˜…"
)
async def list_subscriptions(
    request: Request,
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    category_id: Optional[int] = Query(None, description="åˆ†ç±»IDç­›é€‰"),
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è¿”å›ç”¨æˆ·çš„æ‰€æœ‰æ’­å®¢è®¢é˜…åŠå…¶æœ€æ–°èŠ‚ç›®"""
    service = PodcastService(db, int(user["sub"]))

    # æ„å»ºè¿‡æ»¤å™¨
    filters = PodcastSearchFilter(
        category_id=category_id,
        status=status
    )

    subscriptions, total = await service.list_subscriptions(
        filters=filters,
        page=page,
        size=size
    )

    # è½¬æ¢ä¸ºå“åº”æ¨¡å‹
    subscription_responses = []
    for sub in subscriptions:
        subscription_responses.append(PodcastSubscriptionResponse(**sub))

    pages = (total + size - 1) // size
    response_data = PodcastSubscriptionListResponse(
        subscriptions=subscription_responses,
        total=total,
        page=page,
        size=size,
        pages=pages
    )

    # Check ETag - return 304 if match
    etag_response = await check_etag_precondition(
        request,
        response_data.dict(),
        max_age=900,
        cache_control='private, max-age=900'
    )
    if etag_response:
        return etag_response

    # Return full response with ETag
    return ETagResponse(
        content=response_data.dict(),
        max_age=900,
        cache_control='private, max-age=900'
    )


# === æ‰¹é‡æ“ä½œè·¯ç”± (å¿…é¡»åœ¨å•ä¸ªè®¢é˜…è·¯ç”±ä¹‹å‰ï¼Œé¿å…è·¯å¾„å‚æ•°åŒ¹é…å†²çª) ===

@router.post(
    "/subscriptions/bulk-delete",
    response_model=PodcastSubscriptionBulkDeleteResponse,
    summary="æ‰¹é‡åˆ é™¤æ’­å®¢è®¢é˜…",
    description="æ‰¹é‡åˆ é™¤å¤šä¸ªæ’­å®¢è®¢é˜…åŠå…¶å…³è”çš„å•é›†ã€æ’­æ”¾è¿›åº¦ã€è½¬å½•å’Œå¯¹è¯æ•°æ®"
)
async def delete_subscriptions_bulk(
    request: PodcastSubscriptionBulkDelete,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    æ‰¹é‡åˆ é™¤æ’­å®¢è®¢é˜…

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "subscription_ids": [1, 2, 3]
    }
    ```

    åˆ é™¤é¡ºåºï¼ˆæŒ‰å¤–é”®ä¾èµ–å…³ç³»ï¼‰:
    1. conversations (å¯¹è¯è®°å½•)
    2. playback_progress (æ’­æ”¾è¿›åº¦)
    3. transcriptions (è½¬å½•ä»»åŠ¡)
    4. episodes (å•é›†)
    5. subscriptions (è®¢é˜…)

    æƒé™éªŒè¯ï¼šç¡®ä¿æ‰€æœ‰è®¢é˜…éƒ½å±äºå½“å‰ç”¨æˆ·
    """
    service = PodcastService(db, int(user["sub"]))

    result = await service.remove_subscriptions_bulk(request.subscription_ids)

    return PodcastSubscriptionBulkDeleteResponse(
        success_count=result["success_count"],
        failed_count=result["failed_count"],
        errors=result["errors"],
        deleted_subscription_ids=result["deleted_subscription_ids"]
    )


# === å•ä¸ªè®¢é˜…è·¯ç”± ===

@router.get(
    "/subscriptions/{subscription_id}",
    response_model=PodcastSubscriptionResponse,
    summary="è·å–è®¢é˜…è¯¦æƒ…"
)
async def get_subscription(
    request: Request,
    subscription_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–è®¢é˜…è¯¦æƒ…"""
    service = PodcastService(db, int(user["sub"]))
    details = await service.get_subscription_details(subscription_id)
    if not details:
        raise HTTPException(status_code=404, detail="è®¢é˜…ä¸å­˜åœ¨æˆ–æ— æƒé™")

    response_data = PodcastSubscriptionResponse(**details)

    # Check ETag - return 304 if match
    etag_response = await check_etag_precondition(
        request,
        response_data.dict(),
        max_age=1800,
        cache_control='private, max-age=1800'
    )
    if etag_response:
        return etag_response

    # Return full response with ETag
    return ETagResponse(
        content=response_data.dict(),
        max_age=1800,
        cache_control='private, max-age=1800'
    )


@router.delete(
    "/subscriptions/{subscription_id}",
    summary="åˆ é™¤è®¢é˜…"
)
async def delete_subscription(
    subscription_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """åˆ é™¤è®¢é˜…å’Œå…³è”çš„å•é›†æ•°æ®"""
    service = PodcastService(db, int(user["sub"]))
    success = await service.remove_subscription(subscription_id)
    if not success:
        raise HTTPException(status_code=404, detail="è®¢é˜…ä¸å­˜åœ¨")
    return {"success": True, "message": "è®¢é˜…å·²åˆ é™¤"}


@router.get(
    "/subscriptions/{subscription_id}/schedule",
    response_model=ScheduleConfigResponse,
    summary="Get subscription schedule configuration",
    description="Get the current schedule configuration for a subscription"
)
async def get_subscription_schedule(
    subscription_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """Get subscription schedule configuration"""
    from sqlalchemy import select

    from app.domains.subscription.models import Subscription, UserSubscription

    stmt = (
        select(Subscription, UserSubscription)
        .join(UserSubscription, UserSubscription.subscription_id == Subscription.id)
        .where(
            Subscription.id == subscription_id,
            UserSubscription.user_id == int(user['sub'])
        )
    )

    result = await db.execute(stmt)
    row = result.first()

    if not row:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Subscription not found"
        )

    subscription, user_sub = row

    return ScheduleConfigResponse(
        id=subscription.id,
        title=subscription.title,
        update_frequency=user_sub.update_frequency,
        update_time=user_sub.update_time,
        update_day_of_week=user_sub.update_day_of_week,
        fetch_interval=subscription.fetch_interval,
        next_update_at=user_sub.computed_next_update_at,
        last_updated_at=subscription.last_fetched_at
    )


@router.patch(
    "/subscriptions/{subscription_id}/schedule",
    response_model=ScheduleConfigResponse,
    summary="Update subscription schedule configuration",
    description="Update the schedule configuration for a subscription"
)
async def update_subscription_schedule(
    subscription_id: int,
    schedule_data: ScheduleConfigUpdate,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """Update subscription schedule configuration"""
    from sqlalchemy import select

    from app.domains.subscription.models import Subscription, UserSubscription

    stmt = (
        select(Subscription, UserSubscription)
        .join(UserSubscription, UserSubscription.subscription_id == Subscription.id)
        .where(
            Subscription.id == subscription_id,
            UserSubscription.user_id == int(user['sub'])
        )
    )

    result = await db.execute(stmt)
    row = result.first()

    if not row:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Subscription not found"
        )

    subscription, user_sub = row

    # Update schedule configuration on UserSubscription (user-specific settings)
    user_sub.update_frequency = schedule_data.update_frequency
    user_sub.update_time = schedule_data.update_time
    user_sub.update_day_of_week = schedule_data.update_day_of_week

    if schedule_data.fetch_interval is not None:
        subscription.fetch_interval = schedule_data.fetch_interval

    await db.commit()
    await db.refresh(subscription)
    await db.refresh(user_sub)

    return ScheduleConfigResponse(
        id=subscription.id,
        title=subscription.title,
        update_frequency=user_sub.update_frequency,
        update_time=user_sub.update_time,
        update_day_of_week=user_sub.update_day_of_week,
        fetch_interval=subscription.fetch_interval,
        next_update_at=user_sub.computed_next_update_at,
        last_updated_at=subscription.last_fetched_at
    )


# === å•é›†ç®¡ç† ===

@router.get(
    "/episodes/feed",
    response_model=PodcastFeedResponse,
    summary="è·å–æ’­å®¢ä¿¡æ¯æµ"
)
async def get_podcast_feed(
    request: Request,
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(10, ge=1, le=50, description="æ¯é¡µæ•°é‡"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–ç”¨æˆ·è®¢é˜…çš„æ‰€æœ‰æ’­å®¢åˆ†é›†ï¼ŒæŒ‰å‘å¸ƒæ—¶é—´å€’åºæ’åˆ—"""
    service = PodcastService(db, int(user["sub"]))

    # è·å–ç”¨æˆ·æ‰€æœ‰è®¢é˜…çš„æ’­å®¢åˆ†é›†
    episodes, total = await service.list_episodes(
        filters=None,  # ä¸è¿‡æ»¤ï¼Œè·å–æ‰€æœ‰è®¢é˜…çš„åˆ†é›†
        page=page,
        size=page_size
    )

    # è½¬æ¢ä¸ºå“åº”æ¨¡å‹
    episode_responses = []
    for ep in episodes:
        episode_responses.append(PodcastEpisodeResponse(**ep))

    # è®¡ç®—æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
    has_more = (page * page_size) < total
    next_page = page + 1 if has_more else None

    response_data = PodcastFeedResponse(
        items=episode_responses,
        has_more=has_more,
        next_page=next_page,
        total=total
    )

    # Check ETag - return 304 if match
    etag_response = await check_etag_precondition(
        request,
        response_data.dict(),
        max_age=600,
        cache_control='private, max-age=600'
    )
    if etag_response:
        return etag_response

    # Return full response with ETag
    return ETagResponse(
        content=response_data.dict(),
        max_age=600,
        cache_control='private, max-age=600'
    )


@router.get(
    "/episodes",
    response_model=PodcastEpisodeListResponse,
    summary="è·å–å•é›†åˆ—è¡¨"
)
async def list_episodes(
    subscription_id: Optional[int] = Query(None, description="è®¢é˜…IDç­›é€‰"),
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    has_summary: Optional[bool] = Query(None, description="æ˜¯å¦æœ‰AIæ€»ç»“"),
    is_played: Optional[bool] = Query(None, description="æ˜¯å¦å·²æ’­æ”¾"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–æ’­å®¢å•é›†åˆ—è¡¨"""
    service = PodcastService(db, int(user["sub"]))

    # æ„å»ºè¿‡æ»¤å™¨
    filters = PodcastEpisodeFilter(
        subscription_id=subscription_id,
        has_summary=has_summary,
        is_played=is_played
    )

    episodes, total = await service.list_episodes(
        filters=filters,
        page=page,
        size=size
    )

    # è½¬æ¢ä¸ºå“åº”æ¨¡å‹
    episode_responses = []
    for ep in episodes:
        episode_responses.append(PodcastEpisodeResponse(**ep))

    pages = (total + size - 1) // size
    return PodcastEpisodeListResponse(
        episodes=episode_responses,
        total=total,
        page=page,
        size=size,
        pages=pages,
        subscription_id=subscription_id or 0
    )


@router.get(
    "/episodes/{episode_id}",
    response_model=PodcastEpisodeDetailResponse,
    summary="è·å–å•é›†è¯¦æƒ…"
)
async def get_episode(
    request: Request,
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–å•é›†è¯¦æƒ…ï¼ŒåŒ…å«AIæ€»ç»“ï¼ˆå¦‚æœ‰ï¼‰"""
    service = PodcastService(db, int(user["sub"]))
    episode = await service.get_episode_with_summary(episode_id)
    if not episode:
        raise HTTPException(status_code=404, detail="å•é›†ä¸å­˜åœ¨æˆ–æ— æƒé™")

    response_data = PodcastEpisodeDetailResponse(**episode)

    # Check ETag - return 304 if match
    etag_response = await check_etag_precondition(
        request,
        response_data.dict(),
        max_age=1800,
        cache_control='private, max-age=1800'
    )
    if etag_response:
        return etag_response

    # Return full response with ETag
    return ETagResponse(
        content=response_data.dict(),
        max_age=1800,
        cache_control='private, max-age=1800'
    )


@router.post(
    "/episodes/{episode_id}/summary",
    response_model=PodcastSummaryResponse,
    summary="ç”Ÿæˆ(æˆ–é‡æ–°ç”Ÿæˆ)AIæ€»ç»“"
)
async def generate_summary(
    episode_id: int,
    request: PodcastSummaryRequest,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    åŠŸèƒ½:
    - å¦‚æœæ²¡æœ‰æ€»ç»“ï¼Œç«‹å³ç”Ÿæˆ
    - å¦‚æœæœ‰æ€»ç»“ï¼Œforce=trueæ—¶é‡æ–°ç”Ÿæˆ
    - æ”¯æŒåˆ‡æ¢AIæ¨¡å‹å’Œè‡ªå®šä¹‰æç¤ºè¯
    """
    service = PodcastService(db, int(user["sub"]))
    ai_summary_service = DatabaseBackedAISummaryService(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)
        # ç”Ÿæˆæˆ–é‡æ–°ç”Ÿæˆæ€»ç»“
        summary_result = await ai_summary_service.generate_summary(
            episode_id,
            request.summary_model,
            request.custom_prompt
        )

        # è¿”å›æ€»ç»“å“åº”
        return PodcastSummaryResponse(
            episode_id=episode_id,
            summary=summary_result["summary_content"],
            version="1.0",
            confidence_score=None,
            transcript_used=True,
            generated_at=datetime.utcnow(),
            word_count=len(summary_result["summary_content"].split()),
            model_used=summary_result["model_name"],
            processing_time=summary_result["processing_time"]
        )
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        logger.error(f"Failed to generate summary for episode {episode_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.put(
    "/episodes/{episode_id}/playback",
    response_model=PodcastPlaybackStateResponse,
    summary="æ›´æ–°æ’­æ”¾è¿›åº¦"
)
async def update_playback_progress(
    episode_id: int,
    playback_data: PodcastPlaybackUpdate,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """æ›´æ–°æ’­å®¢æ’­æ”¾è¿›åº¦å’ŒçŠ¶æ€"""
    service = PodcastService(db, int(user["sub"]))
    try:
        result = await service.update_playback_progress(
            episode_id,
            playback_data.position,
            playback_data.is_playing,
            playback_data.playback_rate
        )

        return PodcastPlaybackStateResponse(
            episode_id=episode_id,
            current_position=result["progress"],
            is_playing=result["is_playing"],
            playback_rate=result.get("playback_rate", 1.0),
            play_count=result.get("play_count", 0),
            last_updated_at=result.get("last_updated_at", datetime.utcnow()),
            progress_percentage=result.get("progress_percentage", 0),
            remaining_time=result.get("remaining_time", 0)
        )
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get(
    "/episodes/{episode_id}/playback",
    response_model=PodcastPlaybackStateResponse,
    summary="è·å–æ’­æ”¾çŠ¶æ€"
)
async def get_playback_state(
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–æ’­å®¢æ’­æ”¾çŠ¶æ€"""
    service = PodcastService(db, int(user["sub"]))
    try:
        playback = await service.get_playback_state(episode_id)
        if not playback:
            raise HTTPException(status_code=404, detail="æ’­æ”¾è®°å½•ä¸å­˜åœ¨")

        return PodcastPlaybackStateResponse(**playback)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/summaries/pending",
    response_model=PodcastSummaryPendingResponse,
    summary="å¾…AIæ€»ç»“çš„å•é›†"
)
async def get_pending_summaries(
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """åˆ—å‡ºæ‰€æœ‰éœ€è¦AIæ€»ç»“çš„å•é›†"""
    service = PodcastService(db, int(user["sub"]))
    pending = await service.get_pending_summaries()
    return PodcastSummaryPendingResponse(
        count=len(pending),
        episodes=pending
    )


@router.get(
    "/summaries/models",
    response_model=SummaryModelsResponse,
    summary="è·å–å¯ç”¨çš„AIæ€»ç»“æ¨¡å‹åˆ—è¡¨"
)
async def get_summary_models(
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–æ‰€æœ‰å¯ç”¨çš„AIæ€»ç»“æ¨¡å‹"""
    ai_summary_service = DatabaseBackedAISummaryService(db)

    try:
        models = await ai_summary_service.get_summary_models()

        # è½¬æ¢ä¸ºSummaryModelInfoæ ¼å¼
        model_infos = [
            SummaryModelInfo(
                id=model["id"],
                name=model["name"],
                display_name=model["display_name"],
                provider=model["provider"],
                model_id=model["model_id"],
                is_default=model["is_default"]
            )
            for model in models
        ]

        return SummaryModelsResponse(
            models=model_infos,
            total=len(model_infos)
        )
    except Exception as e:
        logger.error(f"Failed to get summary models: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# === æœç´¢åŠŸèƒ½ ===

@router.get(
    "/search",
    response_model=PodcastEpisodeListResponse,
    summary="æœç´¢æ’­å®¢å†…å®¹"
)
async def search_podcasts(
    q: str = Query(..., min_length=1, description="æœç´¢å…³é”®è¯"),
    search_in: Optional[str] = Query("all", description="æœç´¢èŒƒå›´: title, description, summary, all"),
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """æœç´¢æ’­å®¢å’Œå•é›†å†…å®¹"""
    service = PodcastService(db, int(user["sub"]))

    episodes, total = await service.search_podcasts(
        query=q,
        search_in=search_in,
        page=page,
        size=size
    )

    # è½¬æ¢ä¸ºå“åº”æ¨¡å‹
    episode_responses = []
    for ep in episodes:
        episode_responses.append(PodcastEpisodeResponse(**ep))

    pages = (total + size - 1) // size
    return PodcastEpisodeListResponse(
        episodes=episode_responses,
        total=total,
        page=page,
        size=size,
        pages=pages,
        subscription_id=0
    )


# === ç»Ÿè®¡ä¿¡æ¯ ===

@router.get(
    "/stats",
    response_model=PodcastStatsResponse,
    summary="è·å–æ’­å®¢ç»Ÿè®¡ä¿¡æ¯"
)
async def get_podcast_stats(
    request: Request,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–ç”¨æˆ·çš„æ’­å®¢æ”¶å¬ç»Ÿè®¡"""
    service = PodcastService(db, int(user["sub"]))
    stats = await service.get_user_stats()
    response_data = PodcastStatsResponse(**stats)

    # Check ETag (weak) - return 304 if match
    from app.core.etag import generate_etag, matches_any_etag
    if_none_match = request.headers.get('if-none-match')
    if if_none_match:
        current_etag = generate_etag(response_data.dict(), weak=True)
        if matches_any_etag(current_etag, if_none_match):
            from fastapi import Response
            return Response(
                status_code=304,
                headers={'ETag': current_etag, 'Cache-Control': 'private, max-age=300'}
            )

    # Return full response with weak ETag
    from app.core.etag_response import ETagResponse
    return ETagResponse(
        content=response_data.dict(),
        max_age=300,
        weak=True,
        cache_control='private, max-age=300'
    )


# === æ‰¹é‡æ“ä½œ ===

@router.post(
    "/subscriptions/{subscription_id}/refresh",
    summary="åˆ·æ–°è®¢é˜…"
)
async def refresh_subscription(
    subscription_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """æ‰‹åŠ¨åˆ·æ–°æ’­å®¢è®¢é˜…ï¼Œè·å–æœ€æ–°å•é›†"""
    service = PodcastService(db, int(user["sub"]))
    try:
        new_episodes = await service.refresh_subscription(subscription_id)
        return {
            "success": True,
            "new_episodes": len(new_episodes),
            "message": f"å·²æ›´æ–°ï¼Œå‘ç° {len(new_episodes)} æœŸæ–°èŠ‚ç›®"
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post(
    "/subscriptions/{subscription_id}/reparse",
    summary="é‡æ–°è§£æè®¢é˜…ï¼ˆä¿®å¤è§£æä¸å…¨é—®é¢˜ï¼‰"
)
async def reparse_subscription(
    subscription_id: int,
    force_all: bool = False,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    é‡æ–°è§£æè®¢é˜…çš„æ‰€æœ‰å•é›†ï¼Œç”¨äºä¿®å¤è§£æä¸å…¨çš„é—®é¢˜

    - é»˜è®¤åªè§£æç¼ºå¤±çš„å•é›†
    - force_all=true æ—¶å¼ºåˆ¶é‡æ–°è§£ææ‰€æœ‰å•é›†
    """
    service = PodcastService(db, int(user["sub"]))
    try:
        result = await service.reparse_subscription(subscription_id, force_all=force_all)
        return {
            "success": True,
            "result": result
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# === æ¨èåŠŸèƒ½ ===

@router.get(
    "/recommendations",
    response_model=list[dict],
    summary="è·å–æ’­å®¢æ¨è"
)
async def get_recommendations(
    limit: int = Query(10, ge=1, le=50, description="æ¨èæ•°é‡"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """åŸºäºç”¨æˆ·æ”¶å¬å†å²è·å–æ’­å®¢æ¨è"""
    service = PodcastService(db, int(user["sub"]))
    recommendations = await service.get_recommendations(limit=limit)
    return recommendations


# === è½¬å½•åŠŸèƒ½ ===

@router.post(
    "/episodes/{episode_id}/transcribe",
    status_code=status.HTTP_201_CREATED,
    response_model=PodcastTranscriptionResponse,
    summary="å¯åŠ¨æ’­å®¢å•é›†è½¬å½•",
    description="ä¸ºæŒ‡å®šçš„æ’­å®¢å•é›†å¯åŠ¨éŸ³é¢‘è½¬å½•ä»»åŠ¡"
)
async def start_transcription(
    episode_id: int,
    transcription_request: PodcastTranscriptionRequest,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "force_regenerate": false,
        "chunk_size_mb": 10
    }
    ```

    å·¥ä½œæµç¨‹:
    1. æ£€æŸ¥Redisç¼“å­˜æ˜¯å¦æœ‰æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
    2. æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æœ‰å·²å®Œæˆçš„è½¬å½•
    3. å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ä»»åŠ¡å¹¶ç«‹å³è¿”å›task_id
    4. åå°Celery workerå¼‚æ­¥å¤„ç†è½¬å½•
    """
    service = PodcastService(db, int(user["sub"]))
    transcription_service = DatabaseBackedTranscriptionService(db)
    state_manager = await get_transcription_state_manager()

    try:
        # 1. éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await _validate_episode_and_permission(episode_id, int(user["sub"]), service)

        # 2. FAST PATH: æ£€æŸ¥Redisç¼“å­˜ä¸­çš„æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡
        cached_response = await _check_redis_cached_task(episode_id, state_manager, transcription_service, episode)
        if cached_response:
            return cached_response

        # 3. FAST PATH: æ£€æŸ¥æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„ä»»åŠ¡
        db_response = await _check_existing_db_task(
            episode_id, transcription_request.force_regenerate, transcription_service, episode
        )
        if db_response:
            return db_response

        # 4. å¦‚æœforce_regenerateï¼Œåˆ é™¤ç°æœ‰ä»»åŠ¡
        existing_task = await transcription_service.get_episode_transcription(episode_id)
        if existing_task and transcription_request.force_regenerate:
            logger.info(f"ğŸ”„ [FORCE] Deleting existing task {existing_task.id} for regeneration")
            await db.delete(existing_task)
            await db.commit()

        # 5. è·å–é”å¹¶æ£€æŸ¥æ˜¯å¦å·²æœ‰å…¶ä»–ä»»åŠ¡åœ¨è¿›è¡Œ
        return await _handle_lock_and_create_task(
            episode_id, episode, transcription_request, state_manager, transcription_service, db
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to start transcription for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to start transcription: {str(e)}"
        )


async def _handle_lock_and_create_task(
    episode_id: int,
    episode: PodcastEpisode,
    transcription_request: PodcastTranscriptionRequest,
    state_manager,
    transcription_service: DatabaseBackedTranscriptionService,
    db: AsyncSession
) -> PodcastTranscriptionResponse:
    """å¤„ç†é”é€»è¾‘å¹¶åˆ›å»ºæ–°ä»»åŠ¡

    Args:
        episode_id: å•é›†ID
        episode: æ’­å®¢å•é›†å¯¹è±¡
        transcription_request: è½¬å½•è¯·æ±‚
        state_manager: çŠ¶æ€ç®¡ç†å™¨
        transcription_service: è½¬å½•æœåŠ¡
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        PodcastTranscriptionResponse
    """
    # å°è¯•è·å–åŸå­é”
    lock_acquired = await state_manager.acquire_task_lock(episode_id, 0)

    if not lock_acquired and not transcription_request.force_regenerate:
        return await _handle_locked_episode(episode_id, episode, state_manager, transcription_service)

    # åˆ›å»ºæ–°ä»»åŠ¡
    task = await transcription_service.start_transcription(episode_id, transcription_request.transcription_model)

    # æ›´æ–°Redisé”ä¸ºå®é™…çš„task_id
    await state_manager.release_task_lock(episode_id, 0)
    await state_manager.acquire_task_lock(episode_id, task.id)
    await state_manager.set_episode_task(episode_id, task.id)

    # è®¾ç½®åˆå§‹è¿›åº¦
    await state_manager.set_task_progress(
        task.id,
        TranscriptionStatus.PENDING.value,
        0,
        "Transcription task created, waiting for worker to start..."
    )

    logger.info(f"âœ… [CREATED] New transcription task {task.id} for episode {episode_id}")
    return _build_transcription_response(task, episode)


async def _handle_locked_episode(
    episode_id: int,
    episode: PodcastEpisode,
    state_manager,
    transcription_service: DatabaseBackedTranscriptionService
) -> PodcastTranscriptionResponse:
    """å¤„ç†å·²è¢«é”å®šçš„å•é›†

    Args:
        episode_id: å•é›†ID
        episode: æ’­å®¢å•é›†å¯¹è±¡
        state_manager: çŠ¶æ€ç®¡ç†å™¨
        transcription_service: è½¬å½•æœåŠ¡

    Returns:
        PodcastTranscriptionResponse
    """
    locked_task_id = await state_manager.is_episode_locked(episode_id)

    if locked_task_id:
        logger.info(f"ğŸ”’ [LOCK] Episode {episode_id} already locked by task {locked_task_id}")
        try:
            existing_task = await transcription_service.get_transcription_status(locked_task_id)
            if existing_task:
                logger.info(f"âœ… [LOCK] Returning existing task {existing_task.id} (status: {existing_task.status})")
                return _build_transcription_response(existing_task, episode)
            else:
                logger.warning(f"âš ï¸ [LOCK] Locked task {locked_task_id} not found in DB, cleaning stale lock")
                await _cleanup_stale_lock(state_manager, episode_id, locked_task_id)
        except Exception as e:
            logger.error(f"âŒ [LOCK] Error fetching locked task {locked_task_id}: {e}")
            await _cleanup_stale_lock(state_manager, episode_id, locked_task_id)
    else:
        logger.warning(f"âš ï¸ [LOCK] Episode {episode_id} is locked but no task_id found, cleaning up")
        await _cleanup_stale_lock(state_manager, episode_id, None)

    # å¦‚æœæ¸…ç†é”åï¼Œéœ€è¦ç»§ç»­åˆ›å»ºæ–°ä»»åŠ¡ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ç®€åŒ–å¤„ç†ï¼ŒæŠ›å‡ºå¼‚å¸¸
    raise HTTPException(
        status_code=status.HTTP_409_CONFLICT,
        detail=f"Episode {episode_id} is currently being processed by another task"
    )


async def _cleanup_stale_lock(state_manager, episode_id: int, task_id: Optional[int]) -> None:
    """Clean up a stale lock for an episode.

    Helper function to safely clean up stale locks when a task exists in Redis
    but not in the database, or when the lock state is corrupted.

    Args:
        state_manager: TranscriptionStateManager instance
        episode_id: The episode ID with stale lock
        task_id: The task ID to clean up (None if unknown)
    """
    try:
        if task_id:
            await state_manager.release_task_lock(episode_id, task_id)
        await state_manager.clear_episode_task(episode_id)
        logger.info(f"ğŸ§¹ [LOCK] Cleaned stale lock for episode {episode_id}")
    except Exception as cleanup_error:
        logger.error(f"âŒ [LOCK] Failed to clean stale lock for episode {episode_id}: {cleanup_error}")


def _build_transcription_response(task, episode) -> PodcastTranscriptionResponse:
    """Helper to build transcription response from task and episode"""
    return PodcastTranscriptionResponse(
        id=task.id,
        episode_id=task.episode_id,
        status=task.status.value if hasattr(task.status, 'value') else task.status,
        progress_percentage=task.progress_percentage,
        original_audio_url=task.original_audio_url,
        original_file_size=task.original_file_size,
        transcript_word_count=task.transcript_word_count,
        transcript_duration=task.transcript_duration,
        transcript_content=task.transcript_content,  # â† æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
        error_message=task.error_message,
        error_code=task.error_code,
        download_time=task.download_time,
        conversion_time=task.conversion_time,
        transcription_time=task.transcription_time,
        chunk_size_mb=task.chunk_size_mb,
        model_used=task.model_used,
        created_at=task.created_at,
        started_at=task.started_at,
        completed_at=task.completed_at,
        updated_at=task.updated_at,
        duration_seconds=task.duration_seconds,
        total_processing_time=task.total_processing_time,
        summary_content=task.summary_content,
        summary_model_used=task.summary_model_used,
        summary_word_count=task.summary_word_count,
        summary_processing_time=task.summary_processing_time,
        summary_error_message=task.summary_error_message,
        debug_message=(task.chunk_info or {}).get("debug_message"),
        episode={
            "id": episode.id,
            "title": episode.title,
            "audio_url": episode.audio_url,
            "audio_duration": episode.audio_duration
        }
    )


@router.get(
    "/episodes/{episode_id}/transcription",
    response_model=PodcastTranscriptionDetailResponse,
    summary="è·å–æ’­å®¢å•é›†è½¬å½•çŠ¶æ€å’Œç»“æœ",
    description="æŸ¥è¯¢æŒ‡å®šæ’­å®¢å•é›†çš„è½¬å½•ä»»åŠ¡çŠ¶æ€å’Œè½¬å½•ç»“æœ"
)
async def get_transcription(
    episode_id: int,
    include_content: bool = Query(True, description="æ˜¯å¦åŒ…å«å®Œæ•´è½¬å½•æ–‡æœ¬"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–è½¬å½•ä»»åŠ¡è¯¦æƒ…"""
    service = PodcastService(db, int(user["sub"]))
    transcription_service = DatabaseBackedTranscriptionService(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # è·å–è½¬å½•ä»»åŠ¡
        task = await transcription_service.get_episode_transcription(episode_id)
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="No transcription task found for this episode"
            )

        # æ„å»ºå“åº”æ•°æ®
        response_data = {
            "id": task.id,
            "episode_id": task.episode_id,
            "status": task.status.value if hasattr(task.status, 'value') else task.status,
            "progress_percentage": task.progress_percentage,
            "original_audio_url": task.original_audio_url,
            "original_file_size": task.original_file_size,
            "transcript_word_count": task.transcript_word_count,
            "transcript_duration": task.transcript_duration,
            "error_message": task.error_message,
            "error_code": task.error_code,
            "download_time": task.download_time,
            "conversion_time": task.conversion_time,
            "transcription_time": task.transcription_time,
            "chunk_size_mb": task.chunk_size_mb,
            "model_used": task.model_used,
            "created_at": task.created_at,
            "started_at": task.started_at,
            "completed_at": task.completed_at,
            "updated_at": task.updated_at,
            "duration_seconds": task.duration_seconds,
            "total_processing_time": task.total_processing_time,
            "chunk_info": task.chunk_info,
            "original_file_path": task.original_file_path,
            "episode": {
                "id": episode.id,
                "title": episode.title,
                "audio_url": episode.audio_url,
                "audio_duration": episode.audio_duration
            },
            "debug_message": (task.chunk_info or {}).get("debug_message")
        }

        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦åŒ…å«è½¬å½•å†…å®¹
        if include_content:
            response_data["transcript_content"] = task.transcript_content

        # æ ¼å¼åŒ–æ—¶é—´ä¿¡æ¯
        if task.duration_seconds:
            hours = task.duration_seconds // 3600
            minutes = (task.duration_seconds % 3600) // 60
            seconds = task.duration_seconds % 60
            response_data["formatted_duration"] = f"{hours:02d}:{minutes:02d}:{seconds:02d}"

        if task.total_processing_time:
            response_data["formatted_processing_time"] = f"{task.total_processing_time:.2f} seconds"

        # æ ¼å¼åŒ–æ—¶é—´æˆ³
        response_data["formatted_created_at"] = task.created_at.strftime("%Y-%m-%d %H:%M:%S")
        if task.started_at:
            response_data["formatted_started_at"] = task.started_at.strftime("%Y-%m-%d %H:%M:%S")
        if task.completed_at:
            response_data["formatted_completed_at"] = task.completed_at.strftime("%Y-%m-%d %H:%M:%S")

        return PodcastTranscriptionDetailResponse(**response_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get transcription for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get transcription: {str(e)}"
        )


@router.delete(
    "/episodes/{episode_id}/transcription",
    summary="åˆ é™¤æ’­å®¢å•é›†è½¬å½•ä»»åŠ¡",
    description="åˆ é™¤æŒ‡å®šæ’­å®¢å•é›†çš„è½¬å½•ä»»åŠ¡ï¼Œæ¸…ç†æ•°æ®åº“è®°å½•å’ŒRedisé”"
)
async def delete_transcription(
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """åˆ é™¤è½¬å½•ä»»åŠ¡å¹¶æ¸…ç†ç›¸å…³èµ„æº"""
    service = PodcastService(db, int(user["sub"]))
    transcription_service = DatabaseBackedTranscriptionService(db)
    state_manager = await get_transcription_state_manager()

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # è·å–ç°æœ‰ä»»åŠ¡
        task = await transcription_service.get_episode_transcription(episode_id)

        if task:
            task_id = task.id
            logger.info(f"ğŸ—‘ï¸ [DELETE] Deleting transcription task {task_id} for episode {episode_id}")

            # åˆ é™¤æ•°æ®åº“è®°å½•
            await db.delete(task)
            await db.commit()

            # æ¸…ç†Redisé”å’Œç¼“å­˜
            try:
                # æ¸…ç†episode-taskæ˜ å°„
                await state_manager.clear_episode_task(episode_id)

                # é‡Šæ”¾ä»»åŠ¡é”
                await state_manager.release_task_lock(episode_id, task_id)

                # æ¸…ç†ä»»åŠ¡è¿›åº¦ç¼“å­˜
                await state_manager.clear_task_progress(task_id)

                logger.info(f"âœ… [DELETE] Cleaned up Redis locks for task {task_id}")
            except Exception as redis_error:
                logger.warning(f"âš ï¸ [DELETE] Failed to cleanup Redis: {redis_error}")

            logger.info(f"âœ… [DELETE] Successfully deleted transcription task {task_id} for episode {episode_id}")
        else:
            # å³ä½¿æ²¡æœ‰ä»»åŠ¡è®°å½•ï¼Œä¹Ÿè¦æ¸…ç†å¯èƒ½çš„Redisé”
            logger.info(f"ğŸ§¹ [DELETE] No task found for episode {episode_id}, cleaning up any stale locks")
            try:
                await state_manager.clear_episode_task(episode_id)

                # å°è¯•è·å–é”å®šçš„task_idå¹¶æ¸…ç†
                locked_task_id = await state_manager.is_episode_locked(episode_id)
                if locked_task_id:
                    await state_manager.release_task_lock(episode_id, locked_task_id)
                    await state_manager.clear_task_progress(locked_task_id)

                logger.info(f"âœ… [DELETE] Cleaned up stale locks for episode {episode_id}")
            except Exception as redis_error:
                logger.warning(f"âš ï¸ [DELETE] Failed to cleanup stale locks: {redis_error}")

        return {
            "message": "Transcription task deleted successfully",
            "episode_id": episode_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to delete transcription for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete transcription: {str(e)}"
        )


@router.get(
    "/transcriptions/{task_id}/status",
    response_model=PodcastTranscriptionStatusResponse,
    summary="è·å–è½¬å½•ä»»åŠ¡å®æ—¶çŠ¶æ€",
    description="è·å–è½¬å½•ä»»åŠ¡çš„å®æ—¶è¿›åº¦çŠ¶æ€"
)
async def get_transcription_status(
    task_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–è½¬å½•ä»»åŠ¡çŠ¶æ€"""
    transcription_service = DatabaseBackedTranscriptionService(db)

    try:
        # è·å–è½¬å½•ä»»åŠ¡
        task = await transcription_service.get_transcription_status(task_id)
        if not task:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Transcription task not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ï¼ˆé€šè¿‡episodeè·å–ï¼‰
        service = PodcastService(db, int(user["sub"]))
        episode = await service.get_episode_by_id(task.episode_id, user_id=int(user["sub"]))
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to access this transcription task"
            )

        # æ„å»ºå“åº”æ•°æ®
        status_messages = {
            "pending": "ç­‰å¾…å¼€å§‹è½¬å½•",
            "downloading": "æ­£åœ¨ä¸‹è½½éŸ³é¢‘æ–‡ä»¶",
            "converting": "æ­£åœ¨è½¬æ¢éŸ³é¢‘æ ¼å¼",
            "splitting": "æ­£åœ¨åˆ†å‰²éŸ³é¢‘æ–‡ä»¶",
            "transcribing": "æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«",
            "merging": "æ­£åœ¨åˆå¹¶è½¬å½•ç»“æœ",
            "completed": "è½¬å½•å®Œæˆ",
            "failed": "è½¬å½•å¤±è´¥",
            "cancelled": "è½¬å½•å·²å–æ¶ˆ"
        }

        # è·å–å½“å‰chunkä¿¡æ¯
        current_chunk = 0
        total_chunks = 0
        if task.chunk_info and "chunks" in task.chunk_info:
            total_chunks = len(task.chunk_info["chunks"])
            # æ ¹æ®è¿›åº¦ä¼°ç®—å½“å‰å¤„ç†åˆ°çš„chunk
            if task.status == "transcribing" and task.progress_percentage > 45:
                current_chunk = int(((task.progress_percentage - 45) / 50) * total_chunks)

        # é¢„è®¡å‰©ä½™æ—¶é—´ï¼ˆç®€å•ä¼°ç®—ï¼‰
        eta_seconds = None
        if task.started_at and task.status not in ["completed", "failed", "cancelled"]:
            elapsed = (datetime.utcnow() - task.started_at).total_seconds()
            if task.progress_percentage > 0:
                estimated_total = elapsed / (task.progress_percentage / 100)
                eta_seconds = int(estimated_total - elapsed)

        response_data = {
            "task_id": task.id,
            "episode_id": task.episode_id,
            "status": task.status.value if hasattr(task.status, 'value') else task.status,
            "progress": task.progress_percentage,
            "message": status_messages.get(
                task.status.value if hasattr(task.status, 'value') else task.status,
                "æœªçŸ¥çŠ¶æ€"
            ),
            "current_chunk": current_chunk,
            "total_chunks": total_chunks,
            "eta_seconds": eta_seconds
        }

        return PodcastTranscriptionStatusResponse(**response_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get transcription status for task {task_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get transcription status: {str(e)}"
        )


# === è½¬å½•è°ƒåº¦åŠŸèƒ½ ===

@router.post(
    "/episodes/{episode_id}/transcribe/schedule",
    status_code=status.HTTP_201_CREATED,
    summary="å®‰æ’æ’­å®¢å•é›†è½¬å½•ï¼ˆæ”¯æŒè°ƒåº¦è§„åˆ™ï¼‰",
    description="ä¸ºæŒ‡å®šæ’­å®¢å•é›†å®‰æ’è½¬å½•ä»»åŠ¡ï¼Œæ”¯æŒè‡ªåŠ¨è°ƒåº¦å’Œé¿å…é‡å¤è½¬å½•"
)
async def schedule_episode_transcription_endpoint(
    episode_id: int,
    force: bool = Body(False, description="æ˜¯å¦å¼ºåˆ¶é‡æ–°è½¬å½•ï¼ˆå³ä½¿å·²å­˜åœ¨ç»“æœï¼‰"),
    frequency: str = Body("manual", description="è°ƒåº¦é¢‘ç‡: hourly, daily, weekly, manual"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    å®‰æ’è½¬å½•ä»»åŠ¡ï¼Œæ”¯æŒä»¥ä¸‹ç‰¹æ€§ï¼š
    - è‡ªåŠ¨æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è½¬å½•ç»“æœ
    - é¿å…é‡å¤è½¬å½•å·²æˆåŠŸçš„å†…å®¹
    - æ”¯æŒå®šæ—¶è°ƒåº¦
    - å¯å¼ºåˆ¶é‡æ–°è½¬å½•

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "force": false,
        "frequency": "manual"
    }
    ```
    """
    service = PodcastService(db, int(user["sub"]))

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è½¬å½•ç»“æœ
        existing_transcript = await get_episode_transcript(db, episode_id)
        if existing_transcript and not force:
            return {
                "status": "skipped",
                "message": "Transcription already exists. Use force=true to re-transcribe.",
                "episode_id": episode_id,
                "transcript_preview": existing_transcript[:100] + "..." if len(existing_transcript) > 100 else existing_transcript
            }

        # å®‰æ’è½¬å½•
        scheduler = TranscriptionScheduler(db)
        result = await scheduler.schedule_transcription(
            episode_id=episode_id,
            frequency=ScheduleFrequency(frequency),
            force=force
        )

        return result

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to schedule transcription for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to schedule transcription: {str(e)}"
        )


@router.get(
    "/episodes/{episode_id}/transcript",
    summary="è·å–è½¬å½•æ–‡æœ¬ï¼ˆé¿å…é‡å¤è½¬å½•ï¼‰",
    description="è·å–æ’­å®¢å•é›†çš„è½¬å½•æ–‡æœ¬ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™ç›´æ¥è¿”å›ï¼Œé¿å…é‡å¤è½¬å½•"
)
async def get_episode_transcript_endpoint(
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    æ ¸å¿ƒåŠŸèƒ½ï¼šè¯»å–å·²å­˜åœ¨çš„è½¬å½•æ–‡æœ¬

    é€»è¾‘ï¼š
    1. æ£€æŸ¥PodcastEpisode.transcript_content
    2. æ£€æŸ¥TranscriptionTask.transcript_content
    3. å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›404
    """
    service = PodcastService(db, int(user["sub"]))

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # è·å–è½¬å½•æ–‡æœ¬
        transcript = await get_episode_transcript(db, episode_id)

        if not transcript:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="No transcription found for this episode. Please schedule transcription first."
            )

        return {
            "episode_id": episode_id,
            "episode_title": episode.title,
            "transcript_length": len(transcript),
            "transcript": transcript,
            "status": "success"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get transcript for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get transcript: {str(e)}"
        )


@router.post(
    "/subscriptions/{subscription_id}/transcribe/batch",
    status_code=status.HTTP_201_CREATED,
    summary="æ‰¹é‡è½¬å½•è®¢é˜…çš„æ‰€æœ‰åˆ†é›†",
    description="ä¸ºè®¢é˜…çš„æ‰€æœ‰åˆ†é›†æ‰¹é‡å®‰æ’è½¬å½•ï¼Œè‡ªåŠ¨è·³è¿‡å·²è½¬å½•çš„å†…å®¹"
)
async def batch_transcribe_subscription_endpoint(
    subscription_id: int,
    skip_existing: bool = Body(True, description="æ˜¯å¦è·³è¿‡å·²å­˜åœ¨è½¬å½•çš„åˆ†é›†"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    æ‰¹é‡è½¬å½•åŠŸèƒ½ï¼š
    - è‡ªåŠ¨è·å–è®¢é˜…çš„æ‰€æœ‰åˆ†é›†
    - è·³è¿‡å·²æˆåŠŸè½¬å½•çš„åˆ†é›†
    - æ‰¹é‡å®‰æ’è½¬å½•ä»»åŠ¡

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "skip_existing": true
    }
    ```
    """
    service = PodcastService(db, int(user["sub"]))

    try:
        # éªŒè¯è®¢é˜…å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        subscription = await service.get_subscription_by_id(subscription_id)
        if not subscription:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Subscription {subscription_id} not found"
            )
        # Ownership verified at repository layer

        # æ‰¹é‡è½¬å½•
        result = await batch_transcribe_subscription(
            db,
            subscription_id,
            skip_existing=skip_existing
        )

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to batch transcribe subscription {subscription_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to batch transcribe: {str(e)}"
        )


@router.get(
    "/episodes/{episode_id}/transcription/schedule-status",
    summary="è·å–è½¬å½•è°ƒåº¦çŠ¶æ€",
    description="è·å–æŒ‡å®šåˆ†é›†çš„è½¬å½•ä»»åŠ¡çŠ¶æ€å’Œè°ƒåº¦ä¿¡æ¯"
)
async def get_transcription_schedule_status(
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–è½¬å½•ä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€ä¿¡æ¯"""
    service = PodcastService(db, int(user["sub"]))
    scheduler = TranscriptionScheduler(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # è·å–è½¬å½•çŠ¶æ€
        status = await scheduler.get_transcription_status(episode_id)

        return status

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get transcription status for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get transcription status: {str(e)}"
        )


@router.post(
    "/episodes/{episode_id}/transcription/cancel",
    summary="å–æ¶ˆè½¬å½•ä»»åŠ¡",
    description="å–æ¶ˆæŒ‡å®šåˆ†é›†çš„è½¬å½•ä»»åŠ¡"
)
async def cancel_transcription_endpoint(
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """å–æ¶ˆè½¬å½•ä»»åŠ¡"""
    service = PodcastService(db, int(user["sub"]))
    scheduler = TranscriptionScheduler(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # å–æ¶ˆè½¬å½•
        success = await scheduler.cancel_transcription(episode_id)

        return {
            "success": success,
            "message": "Transcription cancelled" if success else "No active transcription to cancel"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to cancel transcription for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to cancel transcription: {str(e)}"
        )


@router.post(
    "/subscriptions/{subscription_id}/check-new-episodes",
    summary="æ£€æŸ¥å¹¶è½¬å½•æ–°åˆ†é›†",
    description="æ£€æŸ¥è®¢é˜…ä¸­çš„æ–°åˆ†é›†å¹¶è‡ªåŠ¨å®‰æ’è½¬å½•"
)
async def check_and_transcribe_new_episodes(
    subscription_id: int,
    hours_since_published: int = Body(24, description="æ£€æŸ¥å¤šå°‘å°æ—¶å†…å‘å¸ƒçš„åˆ†é›†"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    æ™ºèƒ½æ£€æŸ¥æ–°åˆ†é›†å¹¶è½¬å½•ï¼š
    - æ£€æŸ¥æŒ‡å®šæ—¶é—´èŒƒå›´å†…å‘å¸ƒçš„æ–°åˆ†é›†
    - è‡ªåŠ¨è·³è¿‡å·²è½¬å½•çš„åˆ†é›†
    - æ‰¹é‡å®‰æ’è½¬å½•ä»»åŠ¡

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "hours_since_published": 24
    }
    ```
    """
    service = PodcastService(db, int(user["sub"]))
    scheduler = TranscriptionScheduler(db)

    try:
        # éªŒè¯è®¢é˜…å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        subscription = await service.get_subscription_by_id(subscription_id)
        if not subscription:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Subscription {subscription_id} not found"
            )
        # Ownership verified at repository layer

        # æ£€æŸ¥å¹¶è½¬å½•æ–°åˆ†é›†
        result = await scheduler.check_and_transcribe_new_episodes(
            subscription_id=subscription_id,
            hours_since_published=hours_since_published
        )

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to check new episodes for subscription {subscription_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to check new episodes: {str(e)}"
        )


@router.get(
    "/transcriptions/pending",
    summary="è·å–å¾…å¤„ç†çš„è½¬å½•ä»»åŠ¡",
    description="è·å–æ‰€æœ‰å¾…å¤„ç†çš„è½¬å½•ä»»åŠ¡åˆ—è¡¨"
)
async def get_pending_transcriptions(
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–å½“å‰ç”¨æˆ·æ‰€æœ‰å¾…å¤„ç†çš„è½¬å½•ä»»åŠ¡"""
    scheduler = TranscriptionScheduler(db)

    try:
        # è·å–å¾…å¤„ç†ä»»åŠ¡
        tasks = await scheduler.get_pending_transcriptions()

        # è¿‡æ»¤å½“å‰ç”¨æˆ·çš„ä»»åŠ¡
        service = PodcastService(db, int(user["sub"]))
        user_tasks = []
        for task in tasks:
            episode = await service.get_episode_by_id(task["episode_id"])
            if episode:
                user_tasks.append(task)

        return {
            "total": len(user_tasks),
            "tasks": user_tasks
        }

    except Exception as e:
        logger.error(f"Failed to get pending transcriptions: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get pending transcriptions: {str(e)}"
        )


# === Conversationç›¸å…³ ===

@router.get(
    "/episodes/{episode_id}/conversations",
    response_model=PodcastConversationHistoryResponse,
    summary="è·å–å¯¹è¯å†å²",
    description="è·å–æŒ‡å®šæ’­å®¢å•é›†çš„å¯¹è¯å†å²"
)
async def get_conversation_history(
    episode_id: int,
    limit: int = Query(50, ge=1, le=200, description="è¿”å›çš„æ¶ˆæ¯æ•°é‡é™åˆ¶"),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """è·å–å¯¹è¯å†å²"""
    from app.domains.podcast.conversation_service import ConversationService

    service = PodcastService(db, int(user["sub"]))
    conversation_service = ConversationService(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # è·å–å¯¹è¯å†å²
        messages = await conversation_service.get_conversation_history(
            episode_id=episode_id,
            user_id=int(user["sub"]),
            limit=limit
        )

        # è½¬æ¢ä¸ºå“åº”æ¨¡å‹
        message_responses = [
            PodcastConversationMessage(**msg) for msg in messages
        ]

        return PodcastConversationHistoryResponse(
            episode_id=episode_id,
            messages=message_responses,
            total=len(message_responses)
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get conversation history for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get conversation history: {str(e)}"
        )


@router.post(
    "/episodes/{episode_id}/conversations",
    status_code=status.HTTP_201_CREATED,
    response_model=PodcastConversationSendResponse,
    summary="å‘é€å¯¹è¯æ¶ˆæ¯",
    description="å‘AIåŠ©æ‰‹å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤ï¼Œæ”¯æŒä¸Šä¸‹æ–‡ä¿æŒ"
)
async def send_conversation_message(
    episode_id: int,
    request: PodcastConversationSendRequest,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """
    å‘é€å¯¹è¯æ¶ˆæ¯ï¼š

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "message": "è¿™æœŸæ’­å®¢ä¸»è¦è®²äº†ä»€ä¹ˆï¼Ÿ",
        "model_name": "gpt-4"
    }
    ```
    """
    from app.domains.podcast.conversation_service import ConversationService

    service = PodcastService(db, int(user["sub"]))
    conversation_service = ConversationService(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # å‘é€æ¶ˆæ¯å¹¶è·å–AIå›å¤
        response = await conversation_service.send_message(
            episode_id=episode_id,
            user_id=int(user["sub"]),
            user_message=request.message,
            model_name=request.model_name
        )

        return PodcastConversationSendResponse(**response)

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to send message for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to send message: {str(e)}"
        )


@router.delete(
    "/episodes/{episode_id}/conversations",
    response_model=PodcastConversationClearResponse,
    summary="æ¸…é™¤å¯¹è¯å†å²",
    description="æ¸…é™¤æŒ‡å®šæ’­å®¢å•é›†çš„å¯¹è¯å†å²"
)
async def clear_conversation_history(
    episode_id: int,
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """æ¸…é™¤å¯¹è¯å†å²"""
    from app.domains.podcast.conversation_service import ConversationService

    service = PodcastService(db, int(user["sub"]))
    conversation_service = ConversationService(db)

    try:
        # éªŒè¯æ’­å®¢å•é›†å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        episode = await service.get_episode_by_id(episode_id)
        if not episode:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Episode {episode_id} not found"
            )

        # éªŒè¯ç”¨æˆ·æƒé™ (ownership verified at repository layer)

        # æ¸…é™¤å¯¹è¯å†å²
        deleted_count = await conversation_service.clear_conversation_history(
            episode_id=episode_id,
            user_id=int(user["sub"])
        )

        return PodcastConversationClearResponse(
            episode_id=episode_id,
            deleted_count=deleted_count
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to clear conversation history for episode {episode_id}: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to clear conversation history: {str(e)}"
        )



@router.get(
    "/subscriptions/schedule/all",
    response_model=list[ScheduleConfigResponse],
    summary="Get all subscription schedules",
    description="Get schedule configuration for all user subscriptions"
)
async def get_all_subscription_schedules(
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """Get all subscription schedule configurations"""
    from sqlalchemy import and_

    from app.domains.subscription.models import Subscription, UserSubscription

    stmt = (
        select(Subscription, UserSubscription)
        .join(UserSubscription, UserSubscription.subscription_id == Subscription.id)
        .where(
            and_(
                UserSubscription.user_id == int(user["sub"]),
                UserSubscription.is_archived == False,
                Subscription.source_type.in_(["podcast-rss", "rss"]),
            )
        )
        .order_by(Subscription.created_at)
    )

    result = await db.execute(stmt)
    rows = list(result.all())

    return [
        ScheduleConfigResponse(
            id=sub.id,
            title=sub.title,
            update_frequency=user_sub.update_frequency,
            update_time=user_sub.update_time,
            update_day_of_week=user_sub.update_day_of_week,
            fetch_interval=sub.fetch_interval,
            next_update_at=user_sub.computed_next_update_at,
            last_updated_at=sub.last_fetched_at
        )
        for sub, user_sub in rows
    ]


@router.post(
    "/subscriptions/schedule/batch-update",
    response_model=list[ScheduleConfigResponse],
    summary="Batch update subscription schedules",
    description="Update schedule configuration for multiple subscriptions"
)
async def batch_update_subscription_schedules(
    subscription_ids: list[int] = Body(..., embed=True),
    schedule_data: ScheduleConfigUpdate = Body(...),
    user=Depends(get_token_from_request),
    db: AsyncSession = Depends(get_db_session)
):
    """Batch update schedule configuration for multiple subscriptions"""
    from sqlalchemy import and_

    from app.domains.subscription.models import Subscription, UserSubscription

    stmt = (
        select(Subscription, UserSubscription)
        .join(UserSubscription, UserSubscription.subscription_id == Subscription.id)
        .where(
            and_(
                Subscription.id.in_(subscription_ids),
                UserSubscription.user_id == int(user["sub"]),
                UserSubscription.is_archived == False,
                Subscription.source_type.in_(["podcast-rss", "rss"]),
            )
        )
    )

    result = await db.execute(stmt)
    rows = list(result.all())

    updated_rows: list[tuple] = []
    for sub, user_sub in rows:
        # Update schedule configuration
        user_sub.update_frequency = schedule_data.update_frequency
        user_sub.update_time = schedule_data.update_time
        user_sub.update_day_of_week = schedule_data.update_day_of_week

        if schedule_data.fetch_interval is not None:
            sub.fetch_interval = schedule_data.fetch_interval

        updated_rows.append((sub, user_sub))

    await db.commit()

    # Refresh to get computed properties
    for sub, user_sub in updated_rows:
        await db.refresh(sub)
        await db.refresh(user_sub)

    return [
        ScheduleConfigResponse(
            id=sub.id,
            title=sub.title,
            update_frequency=user_sub.update_frequency,
            update_time=user_sub.update_time,
            update_day_of_week=user_sub.update_day_of_week,
            fetch_interval=sub.fetch_interval,
            next_update_at=user_sub.computed_next_update_at,
            last_updated_at=sub.last_fetched_at
        )
        for sub, user_sub in updated_rows
    ]

# Export router
__all__ = ["router", "podcast_router"]

# Alias for backward compatibility
podcast_router = router
