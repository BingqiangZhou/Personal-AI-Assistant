"""
æ’­å®¢è½¬å½•æœåŠ¡ç®¡ç†å™¨
ä½¿ç”¨æ•°æ®åº“ä¸­çš„AIæ¨¡å‹é…ç½®
"""

import logging
from datetime import datetime, timedelta, timezone
from typing import Any

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.exceptions import ValidationError
from app.domains.ai.models import ModelType
from app.domains.ai.repositories import AIModelConfigRepository
from app.domains.podcast.ai_key_resolver import resolve_api_key_with_fallback
from app.domains.podcast.transcription import (
    PodcastTranscriptionService,
    SiliconFlowTranscriber,
)
from app.domains.podcast.transcription_state import get_transcription_state_manager


logger = logging.getLogger(__name__)


class TranscriptionModelManager:
    """è½¬å½•æ¨¡å‹ç®¡ç†å™¨"""

    def __init__(self, db: AsyncSession):
        self.db = db
        self.ai_model_repo = AIModelConfigRepository(db)

    async def get_active_transcription_model(self, model_name: str | None = None):
        """è·å–æ´»è·ƒçš„è½¬å½•æ¨¡å‹é…ç½®ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰"""
        if model_name:
            # æ ¹æ®åç§°è·å–æŒ‡å®šæ¨¡å‹
            model = await self.ai_model_repo.get_by_name(model_name)
            if (
                not model
                or not model.is_active
                or model.model_type != ModelType.TRANSCRIPTION
            ):
                raise ValidationError(
                    f"Transcription model '{model_name}' not found or not active"
                )
            return model
        else:
            # æŒ‰ä¼˜å…ˆçº§è·å–è½¬å½•æ¨¡å‹åˆ—è¡¨
            active_models = await self.ai_model_repo.get_active_models_by_priority(
                ModelType.TRANSCRIPTION
            )
            if not active_models:
                raise ValidationError("No active transcription model found")
            # è¿”å›ä¼˜å…ˆçº§æœ€é«˜çš„æ¨¡å‹ï¼ˆpriority æ•°å­—æœ€å°çš„ï¼‰
            return active_models[0]

    async def create_transcriber(self, model_name: str | None = None):
        """åˆ›å»ºè½¬å½•å™¨å®ä¾‹"""
        model_config = await self.get_active_transcription_model(model_name)

        # è§£å¯†APIå¯†é’¥
        api_key = await self._get_api_key(model_config)

        # è·å–API URL - å¦‚æœæ¨¡å‹é…ç½®çš„URLä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼
        api_url = model_config.api_url
        if not api_url or api_url.strip() == "":
            from app.core.config import settings

            default_url = "https://api.siliconflow.cn/v1/audio/transcriptions"
            api_url = getattr(settings, "TRANSCRIPTION_API_URL", default_url)
            logger.warning(
                f"âš ï¸ [MODEL] Model {model_config.name} has no api_url configured, using default: {api_url}"
            )
        else:
            logger.info(f"ğŸ”— [MODEL] Using api_url from model config: {api_url}")

        # æ ¹æ®æä¾›å•†åˆ›å»ºå¯¹åº”çš„è½¬å½•å™¨
        if model_config.provider == "siliconflow":
            return SiliconFlowTranscriber(
                api_key=api_key,
                api_url=api_url,
                max_concurrent=model_config.max_concurrent_requests,
            )
        elif model_config.provider == "openai":
            # OpenAIçš„è½¬å½•æœåŠ¡APIæ ¼å¼ç±»ä¼¼ï¼Œå¯ä»¥ä½¿ç”¨ç›¸åŒçš„è½¬å½•å™¨
            return SiliconFlowTranscriber(
                api_key=api_key,
                api_url=api_url,
                max_concurrent=model_config.max_concurrent_requests,
            )
        else:
            # è‡ªå®šä¹‰æä¾›å•†ï¼Œå°è¯•ä½¿ç”¨é€šç”¨è½¬å½•å™¨
            return SiliconFlowTranscriber(
                api_key=api_key,
                api_url=api_url,
                max_concurrent=model_config.max_concurrent_requests,
            )

    async def get_model_info(self, model_name: str | None = None) -> dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        model_config = await self.get_active_transcription_model(model_name)
        return {
            "model_id": model_config.id,
            "name": model_config.name,
            "display_name": model_config.display_name,
            "provider": model_config.provider,
            "model_id_str": model_config.model_id,
            "max_concurrent_requests": model_config.max_concurrent_requests,
            "timeout_seconds": model_config.timeout_seconds,
            "extra_config": model_config.extra_config or {},
        }

    async def list_available_models(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è½¬å½•æ¨¡å‹"""
        active_models = await self.ai_model_repo.get_active_models(
            ModelType.TRANSCRIPTION
        )
        return [
            {
                "id": model.id,
                "name": model.name,
                "display_name": model.display_name,
                "provider": model.provider,
                "model_id": model.model_id,
                "is_default": model.is_default,
            }
            for model in active_models
        ]

    async def _get_api_key(self, model_config) -> str:
        """Get API key with system-key preference and active-model fallback."""
        system_key = None
        if model_config.is_system:
            from app.core.config import settings

            if model_config.provider == "openai":
                system_key = getattr(settings, "OPENAI_API_KEY", "")
            elif model_config.provider == "siliconflow":
                system_key = getattr(settings, "TRANSCRIPTION_API_KEY", "")

        active_models = await self.ai_model_repo.get_active_models(
            ModelType.TRANSCRIPTION
        )
        try:
            return resolve_api_key_with_fallback(
                primary_model=model_config,
                fallback_models=active_models,
                logger=logger,
                invalid_message=(
                    f"No valid API key found. Model '{model_config.name}' has a "
                    "placeholder/invalid API key, and no alternative models with "
                    "valid API keys were found. Please configure a valid API key "
                    "for at least one TRANSCRIPTION model."
                ),
                provider_key_prefix={"siliconflow": "sk-"},
                system_key=system_key,
            )
        except ValueError as exc:
            raise ValidationError(str(exc)) from exc


class DatabaseBackedTranscriptionService(PodcastTranscriptionService):
    """åŸºäºæ•°æ®åº“é…ç½®çš„è½¬å½•æœåŠ¡"""

    def __init__(self, db: AsyncSession):
        super().__init__(db)
        self.model_manager = TranscriptionModelManager(db)

    async def start_transcription(
        self, episode_id: int, model_name: str | None = None, force: bool = False
    ):
        """å¯åŠ¨è½¬å½•ä»»åŠ¡ï¼Œæ”¯æŒæŒ‡å®šæ¨¡å‹å’Œå¼ºåˆ¶æ¨¡å¼"""
        # è·å–æ¨¡å‹ä¿¡æ¯ï¼ˆéªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼‰
        if model_name:
            await self.model_manager.get_active_transcription_model(model_name)

        # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„ä»»åŠ¡å¯ä»¥é‡è¯•ï¼ˆå¢é‡æ¢å¤ï¼‰
        from sqlalchemy import select

        from app.domains.podcast.models import TranscriptionTask

        stmt = (
            select(TranscriptionTask)
            .where(TranscriptionTask.episode_id == episode_id)
            .order_by(TranscriptionTask.created_at.desc())
        )

        result = await self.db.execute(stmt)
        existing_task = result.scalar_one_or_none()

        # å¦‚æœæœ‰ PENDING çŠ¶æ€çš„ä»»åŠ¡ï¼Œé‡æ–°å‘é€åˆ° Celery
        if (
            existing_task and existing_task.status == "pending" and not force
        ):  # Use string comparison
            # Check if this task already owns the lock before re-dispatching
            state_manager = await get_transcription_state_manager()
            locked_task_id = await state_manager.is_episode_locked(episode_id)

            if locked_task_id == existing_task.id:
                # Task already owns lock and is being processed, don't re-dispatch
                logger.info(
                    f"ğŸ”„ [TRANSCRIPTION] PENDING task {existing_task.id} already owns lock, skipping re-dispatch"
                )
                return existing_task
            elif locked_task_id is not None:
                # Different task owns the lock
                logger.warning(
                    f"âš ï¸ [TRANSCRIPTION] Episode {episode_id} locked by different task {locked_task_id}, cannot re-dispatch task {existing_task.id}"
                )
                return existing_task

            # No lock exists, safe to dispatch
            logger.info(
                f"ğŸ”„ [TRANSCRIPTION] Re-sending existing PENDING task {existing_task.id} to Celery"
            )
            # æäº¤åˆ° Celery é˜Ÿåˆ—
            from app.domains.podcast.tasks import process_audio_transcription

            # è·å–æ¨¡å‹é…ç½® IDï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            ai_repo = AIModelConfigRepository(self.db)
            model_config = None
            if model_name:
                model_config = await ai_repo.get_by_name(model_name)
            if not model_config:
                active_models = await ai_repo.get_active_models_by_priority(
                    ModelType.TRANSCRIPTION
                )
                model_config = active_models[0] if active_models else None
            config_db_id = model_config.id if model_config else None

            process_audio_transcription.delay(existing_task.id, config_db_id)
            logger.info(
                f"ğŸš€ [TRANSCRIPTION] Re-dispatched PENDING task {existing_task.id} to Celery"
            )

            return existing_task

        # å¦‚æœæœ‰å¤±è´¥çš„ä»»åŠ¡ä¸”ä¸æ˜¯ force æ¨¡å¼ï¼Œå°è¯•é‡ç”¨å®ƒ
        if (
            existing_task
            and existing_task.status in ["failed", "cancelled"]
            and not force
        ):  # Use string comparison
            # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            import os

            temp_episode_dir = os.path.join(self.temp_dir, f"episode_{episode_id}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ä¸´æ—¶æ–‡ä»¶
            has_temp_files = False
            if os.path.exists(temp_episode_dir):
                # æ£€æŸ¥æ˜¯å¦æœ‰ downloaded æˆ– converted æ–‡ä»¶
                for _, _, files in os.walk(temp_episode_dir):
                    if files:
                        has_temp_files = True
                        break

            if has_temp_files:
                # Check if episode is locked before re-dispatching
                state_manager = await get_transcription_state_manager()
                locked_task_id = await state_manager.is_episode_locked(episode_id)

                if locked_task_id is not None:
                    # Episode is locked by another task
                    logger.warning(
                        f"âš ï¸ [TRANSCRIPTION] Episode {episode_id} locked by task {locked_task_id}, cannot re-dispatch failed task {existing_task.id}"
                    )
                    return existing_task

                # é‡ç”¨ç°æœ‰ä»»åŠ¡ï¼Œé‡ç½®çŠ¶æ€ä¸º PENDING
                logger.info(
                    f"ğŸ”„ [TRANSCRIPTION] Reusing existing failed task {existing_task.id} with temp files for incremental recovery"
                )
                existing_task.status = "pending"  # Use string value
                existing_task.error_message = None
                existing_task.started_at = None
                existing_task.completed_at = None
                existing_task.progress_percentage = 0
                existing_task.current_step = "not_started"
                await self.db.commit()
                await self.db.refresh(existing_task)

                # æäº¤åˆ° Celery é˜Ÿåˆ—
                from app.domains.podcast.tasks import process_audio_transcription

                # è·å–æ¨¡å‹é…ç½® IDï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
                ai_repo = AIModelConfigRepository(self.db)
                model_config = None
                if model_name:
                    model_config = await ai_repo.get_by_name(model_name)
                if not model_config:
                    active_models = await ai_repo.get_active_models_by_priority(
                        ModelType.TRANSCRIPTION
                    )
                    model_config = active_models[0] if active_models else None
                config_db_id = model_config.id if model_config else None

                process_audio_transcription.delay(existing_task.id, config_db_id)
                logger.info(
                    f"ğŸš€ [TRANSCRIPTION] Re-dispatched existing task {existing_task.id} for incremental recovery"
                )

                return existing_task

        # æ²¡æœ‰å¯é‡ç”¨çš„ä»»åŠ¡ï¼Œåˆ›å»ºæ–°ä»»åŠ¡
        task, config_db_id = await super().create_transcription_task_record(
            episode_id, model_name, force
        )

        # æäº¤åˆ° Celery é˜Ÿåˆ—
        from app.domains.podcast.tasks import process_audio_transcription

        # ä½¿ç”¨ delay() å¼‚æ­¥å‘é€ä»»åŠ¡
        # task.id æ˜¯æ•°æ®åº“ä¸»é”®ï¼Œconfig_db_id æ˜¯ç›¸å…³æ¨¡å‹é…ç½®ID
        process_audio_transcription.delay(task.id, config_db_id)

        logger.info(
            f"ğŸš€ [TRANSCRIPTION] Dispatched Celery task for transcription task {task.id} (config_id={config_db_id})"
        )

        return task

    async def get_transcription_models(self):
        """è·å–å¯ç”¨çš„è½¬å½•æ¨¡å‹åˆ—è¡¨"""
        return await self.model_manager.list_available_models()

    async def delete_episode_transcription(self, episode_id: int) -> int | None:
        """Delete latest transcription task for an episode and return task id."""
        task = await self.get_episode_transcription(episode_id)
        if not task:
            return None
        task_id = task.id
        await self.db.delete(task)
        await self.db.commit()
        return task_id

    async def reset_stale_tasks(self):
        """
        é‡ç½®æ‰€æœ‰å¤„äºä¸­é—´çŠ¶æ€çš„ä»»åŠ¡ä¸ºå¤±è´¥
        ç”¨äºæœåŠ¡å™¨é‡å¯åæ¸…ç†åƒµå°¸ä»»åŠ¡

        æ³¨æ„ï¼šåªé‡ç½®å·²å®é™…å¼€å§‹æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆstarted_at ä¸ä¸ºç©ºï¼‰
        æœªå¼€å§‹æ‰§è¡Œçš„ PENDING ä»»åŠ¡ä¿æŒåŸçŠ¶æ€ï¼Œå¯ä»¥è¢«é‡æ–°è°ƒåº¦
        """
        from sqlalchemy import and_, update

        from app.domains.podcast.models import TranscriptionTask

        # ä»»åŠ¡çŠ¶æ€é˜ˆå€¼ï¼šåªé‡ç½®è¶…è¿‡è¿™ä¸ªæ—¶é—´çš„ä»»åŠ¡ï¼ˆ5åˆ†é’Ÿï¼‰
        # é¿å…é‡ç½®åˆšåˆšåˆ›å»ºä½†è¿˜æ²¡æ‰§è¡Œçš„ä»»åŠ¡
        # Note: Use datetime.now(timezone.utc) to match the database column type (naive datetime)
        stale_threshold = datetime.now(timezone.utc) - timedelta(minutes=5)

        # åªæœ‰å®é™…å¼€å§‹æ‰§è¡Œçš„ä»»åŠ¡çŠ¶æ€æ‰åº”è¯¥è¢«é‡ç½®
        # PENDING çŠ¶æ€å¦‚æœ started_at ä¸ºç©ºï¼Œè¯´æ˜ä»»åŠ¡è¿˜æ²¡å¼€å§‹ï¼Œä¸åº”è¯¥è¢«é‡ç½®
        # åœ¨æ–°æ¨¡å‹ä¸­ï¼Œæ‰€æœ‰è¿›è¡Œä¸­çš„ä»»åŠ¡éƒ½æ˜¯ in_progress çŠ¶æ€ï¼Œcurrent_step è®°å½•å…·ä½“æ­¥éª¤
        in_progress_statuses = ["in_progress"]  # Use string values

        try:
            # é‡ç½®å·²å¼€å§‹æ‰§è¡Œä½†è¶…æ—¶çš„ä»»åŠ¡
            stmt = (
                update(TranscriptionTask)
                .where(
                    and_(
                        TranscriptionTask.status.in_(in_progress_statuses),
                        TranscriptionTask.started_at.isnot(None),
                        TranscriptionTask.updated_at < stale_threshold,
                    )
                )
                .values(
                    status="failed",  # Use string value
                    error_message="Task interrupted by server restart",
                    updated_at=datetime.now(timezone.utc),
                    completed_at=datetime.now(timezone.utc),
                )
            )

            result = await self.db.execute(stmt)
            await self.db.commit()

            if result.rowcount > 0:
                logger.warning(
                    f"Reset {result.rowcount} stale transcription tasks to FAILED (in-progress tasks that timed out)"
                )

            # å¯¹äº PENDING çŠ¶æ€çš„ä»»åŠ¡ï¼Œå¦‚æœåˆ›å»ºæ—¶é—´å¾ˆä¹…äº†ä½†ä»æœªå¼€å§‹æ‰§è¡Œï¼Œä¹Ÿæ ‡è®°ä¸ºå¤±è´¥
            # è¿™äº›ä»»åŠ¡å¯èƒ½æ˜¯ç”±äºæŸäº›åŸå› ä»æœªè¢«è°ƒåº¦æ‰§è¡Œ
            pending_stale_threshold = datetime.now(timezone.utc) - timedelta(
                hours=1
            )  # 1å°æ—¶
            stmt2 = (
                update(TranscriptionTask)
                .where(
                    and_(
                        TranscriptionTask.status == "pending",  # Use string value
                        TranscriptionTask.started_at.is_(None),  # ä»æœªå¼€å§‹
                        TranscriptionTask.created_at
                        < pending_stale_threshold,  # åˆ›å»ºè¶…è¿‡1å°æ—¶
                    )
                )
                .values(
                    status="failed",  # Use string value
                    error_message="Task was never scheduled for execution",
                    updated_at=datetime.now(timezone.utc),
                    completed_at=datetime.now(timezone.utc),
                )
            )

            result2 = await self.db.execute(stmt2)
            await self.db.commit()

            if result2.rowcount > 0:
                logger.warning(
                    f"Reset {result2.rowcount} stale PENDING tasks to FAILED (never started)"
                )

        except Exception as e:
            logger.error(f"Failed to reset stale tasks: {str(e)}")

    async def cleanup_old_temp_files(self, days: int = 7):
        """
        æ¸…ç†æ—§çš„ä¸´æ—¶æ–‡ä»¶
        æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„å¤±è´¥æˆ–å·²å–æ¶ˆä»»åŠ¡çš„ä¸´æ—¶æ–‡ä»¶

        Args:
            days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤7å¤©
        """
        import os
        import shutil

        from sqlalchemy import and_

        from app.core.config import settings
        from app.domains.podcast.models import TranscriptionTask

        temp_dir = getattr(settings, "TRANSCRIPTION_TEMP_DIR", "./temp/transcription")
        temp_dir_abs = os.path.abspath(temp_dir)

        try:
            if not os.path.exists(temp_dir_abs):
                logger.info(
                    f"ğŸ§¹ [CLEANUP] Temp directory does not exist: {temp_dir_abs}"
                )
                return {"cleaned": 0, "freed_bytes": 0}

            # è·å–éœ€è¦æ¸…ç†çš„episode_idåˆ—è¡¨
            # æ¡ä»¶ï¼šå¤±è´¥/å·²å–æ¶ˆçš„ä»»åŠ¡ï¼Œä¸”è¶…è¿‡æŒ‡å®šå¤©æ•°
            stale_threshold = datetime.now(timezone.utc) - timedelta(days=days)
            stmt = (
                select(TranscriptionTask.episode_id)
                .where(
                    and_(
                        TranscriptionTask.status.in_(
                            ["failed", "cancelled"]
                        ),  # Use string values
                        TranscriptionTask.completed_at < stale_threshold,
                    )
                )
                .distinct()
            )

            result = await self.db.execute(stmt)
            episode_ids_to_cleanup = [row[0] for row in result.all()]

            cleaned_count = 0
            freed_bytes = 0

            for episode_id in episode_ids_to_cleanup:
                temp_episode_dir = os.path.join(temp_dir_abs, f"episode_{episode_id}")

                if os.path.exists(temp_episode_dir):
                    try:
                        # è®¡ç®—ç›®å½•å¤§å°
                        dir_size = sum(
                            os.path.getsize(os.path.join(dirpath, filename))
                            for dirpath, _, filenames in os.walk(temp_episode_dir)
                            for filename in filenames
                            if os.path.isfile(os.path.join(dirpath, filename))
                        )

                        # åˆ é™¤ç›®å½•
                        shutil.rmtree(temp_episode_dir)
                        cleaned_count += 1
                        freed_bytes += dir_size
                        logger.info(
                            f"ğŸ§¹ [CLEANUP] Removed old temp directory for episode {episode_id}: {temp_episode_dir} ({dir_size / 1024 / 1024:.2f} MB)"
                        )

                    except Exception as e:
                        logger.error(
                            f"âš ï¸ [CLEANUP] Failed to remove temp directory for episode {episode_id}: {e}"
                        )

            logger.info(
                f"ğŸ§¹ [CLEANUP] Summary: Cleaned {cleaned_count} old temp directories, freed {freed_bytes / 1024 / 1024:.2f} MB"
            )

            return {
                "cleaned": cleaned_count,
                "freed_bytes": freed_bytes,
                "freed_mb": round(freed_bytes / 1024 / 1024, 2),
            }

        except Exception as e:
            logger.error(f"âŒ [CLEANUP] Failed to cleanup old temp files: {str(e)}")
            raise
